\documentclass[10pt, oneside]{article} 
\usepackage{amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry, esint, float}


\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}  

\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbZ}{\mathbb{Z}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}
\newcommand{\scA}{\mathscr{A}}
\newcommand{\curl}{\text{curl}}

\theoremstyle{definition}
\newtheorem{exmp}{Example}[section]
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}
\input{paolo-pset.tex}



\title{UChicago Markov Chains, Martingales, and Brownian Motion Notes: 23500}
\author{Notes by AgustÃ­n Esteva, Lectures by Stephen Yearwood, Book by Greg Lawler}
\date{Academic Year 2024-2025}

\begin{document}

\maketitle
\tableofcontents

\vspace{.25in}


\newpage
\section{Lectures}

\subsection{Monday, Mar 24: Markov Processes: Basic Definitions and Examples}
He is from Trinidad and Tobago. 
\begin{defn}
    A \textbf{stochastic process}  is a collection of random variables $\{X_t\}_{t \in T}$ indexed by time, where each $X_t$ takes values in $S$
\end{defn}
We call $S$ our \textit{state space}. In discrete time, it should be obvious that $T = \bbN_0^*$ (where $\bbN_0^*$ is when on goscale the naturals by a constant) and $T = [0, \bbR)$ in continuous time. We say that $S$ is a discrete space if it is countable and continuous if it is $\bbR^d.$
\begin{rem}
    In order to characterize the distribution of $\{X_n\},$ we must specify $\mathbb{P}\{X_0 = S_0, \dots, X_n = S_n\}$ for all $n \in \bbN$ and for all $S_0, \dots, S_n \in S.$ It is much easier work with conditional probability. We will see that with Markov Chains, the Markov Property guarantees that we only need to worry about the distribution of $X_{n-1}$ to figure out $X_n.$
\end{rem}
\begin{defn}
    If $E,F$ are events with $\mathbb{P}\{F\} >0,$ then the \textbf{conditional probability} of $E$ given $F$ is 
    \[\mathbb{P}(E | F) = \frac{\mathbb{P}(E \cap F)}{\mathbb{P}(F)}\]
\end{defn}
\begin{prop}
    (Law of Total Probability) Recall that if $(B_n) \in S$ is a sequence of mutually exclusive and exhaustive events, then 
    \[P(A) = \sum_{n=1}^\infty P(A \cap B_n) = \sum_{n=1}^\infty P(A \mid B_n)P(B_n)\]
\end{prop}

\begin{defn}
    A stochastic process is called a \textbf{Markov Chain} if for all $n \in \bbN,$ and for all $S_0, \dots, S_n \in S,$ we have that 
    \[\bbP(X_n = S_n |  X_0= S_0, \dots, X_{n-1}= S_{n-1}) = \bbP(X_n = S_n | X_{n-1} =S_{n-1})\]
\end{defn}
\begin{defn}
    A Markov Chain $\{X_n\}$ is \textbf{time-homogeneous} if for all $n\in N,$ for all $x,y \in S,$ 
    \[\bbP(X_n = y | X_{n-1} = x) = \bbP(X_1 = y | X_0 = x)\]
\end{defn}
Thus, it does not matter when you get to the states, and so we can just specify the distribution of $X_0$ and the transition probability;
\[p(x,y) := \bbP(X_1 = y | X_0 = x)\]
and then scale to find the rest.
\begin{exmp}
    Let $S = \{0,1\}.$ A Markov chain taking values in $S$ specified by $p = p(0,1)$ and $q = p(1,0).$ It is obvious that $p(0,0) = 1-p$ and $q(1,1) = 1-q.$
\end{exmp}
\begin{exmp}
    Let $S = \bbZ.$ Let $\{X_n\}_{n\geq 0}$ be defined by $X_0 = X_1 = X_2 =0$ and for $n\geq 3,$ then 
    \[X_n = \begin{cases}
        X_{n-1} + 1,\\
        X_{n-1} - 1,\\
        X_{n-3}
    \end{cases}\]
    each with with probability $1/3.$ This is NOT a Markov Process since $X_n$ can depend on $X_{n-3}.$
\end{exmp}

\begin{defn}
    The $n-$step transition probabilities 
    \[p^n(x,y) = \bbP(X_n = y | X_0 = x).\]
\end{defn}
That is, if we start at $x,$ what is the probability that the $n$th step is $y$?
\begin{prop}
    For all $m,n \in \bbN$ and for all $x,y \in S,$ then 
    \[p^{n + m}(x,y) = \sum_{z\in S}p^n(x,z)p^m(z,y)\]
\end{prop}
\begin{proof}
    We have that by time homogeneity, 
    \[p^n(x,z)p^m(z,y) = \bbP\{X_n = z \mid X_0 = x\} \bbP\{X_{n + m} = y \mid X_n = z\}\] By the Markov Property,
    \[\bbP\{X_{n + m} = y \mid X_n = z\} = \bbP\{X_{n + m} = y \mid X_n = z, X_0 = x\}\] By Bayes' rule:
    \[\bbP\{X_n = z \mid X_0 = x\}\bbP\{X_{n + m} = y \mid X_n = z, X_0 = x\} = \bbP\{X_{n +m} = y, X_n = z \mid X_0 = x\}\] Thus, 
    \[\sum_{z \in S}p^n(x,z)p^m(z,y) = \sum_{z\in S}\bbP\{X_{n +m} = y, X_n = z \mid X_0 = x\} = \bbP\{X_{n + m} = y \mid X_0 = x\} = p^{n + m}(x,y)\]
\end{proof}
\begin{defn}
    The \textbf{transition matrix} of a Markov Chain the the $N \times N$ matrix $P$ whose $ij$ entry is $p(i,j).$
\end{defn}
\begin{prop}
    For each $n \in \bbN,$ $P^n$ is the matrix whose $ij$ entry is $p^n(i,j).$
\end{prop}
\begin{proof}
    We prove by induction. It is trivial for $n = 1.$ Assume it is true for any general $n-1.$ Thus, the $ij$ entry of $P^n = P^{n-1}P$ is \[\sum_{k=1}^n P^{n-1}_{ik}P_{kj} = \sum_{k=1}^n p^{n-1}(i,k)p(k,j) = p^n(i,j),\] where the last equality comes from Proposition 1.
\end{proof}

\newpage
\subsection{Wednesday, Mar 26: Recurrence and Transience for Finite State Space}
We illustrate the stuff from last class with a simple example:
\begin{exmp}
    Consider the two state Markov chain with $S = \{0,1\}$ and 
    \[p(0,1) = \frac{1}{3}, \quad p(1,0) = \frac{1}{2},\] then 
    \[P = \begin{pmatrix}
        p(0,0) & p(0,1)\\
        p(1,0) & p(1,1) 
    \end{pmatrix} = \begin{pmatrix}
        \frac{2}{3} & \frac{1}{3}\\
        \frac{1}{2} & \frac{1}{2}
    \end{pmatrix},\] then 
    \[\bbP\{X_3 = 0 | X_0 = 0\} = p^3(0,0) = \frac{65}{108}\]
\end{exmp}
For the following, we consider a Markov chain $\{X_n\}$ with state space $S.$
\begin{defn}
    Two states $x,y \in S$ \textbf{communicate} if there exists $m,n >0$ such that $p^n(x,y) >0$ and $p^m(y,x) > 0 .$ We write $x \leftrightarrow y.$
\end{defn}
\begin{rem}
    Communication is an equivalence relation, and so we can partition $S$ into a disjoint union of communication classes by modding out the communication classes.
\end{rem}
\begin{defn}
    A communication class $c$ is \textbf{recurrent} if $p(x,y) = 0$ for all $x\in C$ and $y \in S\setminus\{C\}.$ Otherwise, we say that the communication class is \textbf{transient}.
\end{defn}
In other words, if $C$ is recurrent, then the chain never leaves. If it is transcient, then there is no problem leaving.


\begin{defn}
    A Markov chain is \textbf{irreducible} if there is only one communication class.
\end{defn}

\begin{exmp}
    Consider a Markov chain with $S  = \{1,2,3,4,5\}$ and 
    \[P = \begin{pmatrix}
        \frac{1}{5} & \frac{1}{5} & 0 & 0 & \frac{3}{5}\\
        0 & 0 & 0 & 0 & 1\\
        0 & 0 & \frac{1}{2} & \frac{1}{2} & 0\\
        0 & 0 & \frac{1}{4} & \frac{3}{4} & 0\\
        \frac{1}{2} & \frac{1}{4} & \frac{1}{4} & 0 & 0
    \end{pmatrix}\] then 
    \[C_1 = \{1,2,5\}, \qquad C_2 = \{3,4\}\] and $C_1$ is transient and $C_2$ is recurrent
\end{exmp}

\begin{exmp} (Gambler's ruin)
    Consider the random walk on $S = \{0,1,2, \dots, N\}$ with absorbing boundary, and transition probability
    \[p(x,x+1) = p(x, x-1) = \frac{1}{2}, \quad x\in \{1,2,\dots, N-1\}\] and 
    \[p(0,0) = p(N,N) = 1\]

    $\{1,\dots, N-1\}$ is a transient communication class, while $\{0\}, \{N\}$ are both recurrent communication classes.
\end{exmp}

\begin{prop}
    Suppose $S$ is finite. If $C$ is a recurrent communication class, then if $\{X_n\}$ starts in $C,$ with probability $1,$ $\{X_n\}$ visits every state in $C$ infinitely often. That is, for each $x,y \in C,$ $\bbP\{X_n = y \text{ i.o.} \; | \; X_0 = x\} = 1.$
\end{prop}
\begin{proof}
    Since $C$ is a communication class, then for every $z \in C,$ there exists some $n_z \in \bbN$ such that $p^{n_z}(z,y) >0.$ Let $n = \max\{n_z\; \forall z \in C\},$ and $q = \min\{p^{n_z}(z,y)\; | \; z\in C\}.$ Note that this quantities necessarily exist because $S$ is finite. Let $E_k = \{X_i = y, \; | \; i \in \{(k-1)n + 1, (k-1)n + 2\, \dots (k-1)nk\}\}.$ Then for states $s_0, s_1, \dots, s_{nk} \in S,$ we have that 
    \[\bbP\{E_{k+1} \: | \: X_0 = s_0, X_1 = s_1, \dots, X_{nk} = S_{nk}\} = \bbP\{E_1 \; | \; X_0 = s_{nk}\} \geq q.\] For $M, N \in \bbN$ with $M > N,$ we have that 
    \begin{align*}
      \bbP\{E_k \text{ does not occur for any any } k \in \{N, N + 1, \dots, M\}\} &= \bbP\{\bigcap_{k=N}^M E_k^c\}  \\
      &= \bbP\{E_M^c \:  | \: \bigcap_{k = N}^{M-1}E_k\}\bbP\{\bigcap_{K=N}^{M-1}E_k\}\\
      &\leq (1-q)\bbP\{\bigcap_{K=N}^{M-1}E_k\} \\
      &\leq\dots\leq (1-q)^{M-N} \to 0
    \end{align*}
\end{proof}
\begin{prop}
    Suppose $S$ is finite. If $C$ is a transient communication class, then w.p. 1, $X$ eventually leaves $C$ and never returns.
\end{prop}

\begin{rem}
    In fact, there exists a $c>0$ such that if $X_0 = x$ and $C$ is transient, then 
    \[\bbP\{X_n \text{ exits $C$ before time $n$} \geq 1- e^{-cn}\}\] Thus, if we let 
    \[\tau = \inf\{n \geq 0 : X_n \notin C\},\] then 
    \[\bbP\{\tau \geq n\} = 1- \bbP\{X_n \text{ exits $C$ before time $n$} \leq 1 - (1-e^{-cn}) = e^{-cn}\to 0\] as $n\to \infty.$ 
\end{rem}

\newpage
\subsection{Friday, Mar 28: The Strong Markov Property}

\begin{defn}
    A random time $\tau \in \bbN_0 \cup \{\infty\}$ is called a \textbf{stopping time} if, for all $n \in \bbN,$ the event $\{\tau = n\}$ is determined by $X_0, X_1, \dots, X_n.$ 
\end{defn}
\begin{exmp}
\begin{enumerate}
    \item (The Hitting Time) \[\tau = \min\{n \mid X_n = x\}, \quad x\in S.\]
    In the Gambler's ruin model, where the gambler starts with $k-$dollars and gambles all the way to $N$ or $0$ dollars, the hitting time is the first the the gambler reaches $\$1$.
    \item $\tau = k^\text{th}$ time for which $X_n \in A,$ $k\in \bbN,$ $A \subset S.$
    \item $\tau = \min\{\tau_1, \tau_2\},$ where $\tau_1$ and $\tau_2$ are stopping times. 
    \item Let $N \in \bbN,$ $x\in S,$ $\tau$ be the last time $n \leq N$ for which $X_n = x,$ and $\tau  = 0$ if no such time exists. $\tau$ is NOT a stopping time because it  depends on stuff in the future.
\end{enumerate}
\end{exmp}

\begin{thm}
    (Strong Markov Property) Let $\tau$ be a stopping time for $\{X_n\}.$ Let $n \geq 0,$ $m\geq 1,$ $x_n \dots, x_n \in S$ such that 
    \[\bbP\{X_0 = x_0, \dots, X_\tau = X_n\} >0,\] and 
    let $y_1, \dots, y_m \in S.$ Then 
    \[\bbP\{X_{\tau + 1} = y, \dots, X_{\tau + m} = y_m\mid X_0 = x_0, \dots, X_\tau = x_n\} =\bbP\{X_{1} = y, \dots, X_{ m} = y_m\mid X_0 = x_n\}\]
\end{thm}
\begin{proof}
    The event $\{X_0 = x_0, \dots, X_\tau = x_n\}$ is the same as the event $\{X_0 = x_0, \dots, X_n = x_n\}$ and $\{\tau = n\}.$ Since $\tau$ is a stopping time determined where the event $\{\tau = n\}$ by $\{X_0, \dots, X_n\}.$ Thus, we get that the events $\{X_0 = x_0, \dots, X_\tau = x_n\} = \{X_0 = x_0, \dots, X_n = n\}\cap \{\tau = n\},$ then 
    \begin{align*}
        \bbP\{X_{\tau + 1} = y_1, \dots, X_{\tau  + m} = y_m \mid X_0 = x_0, \dots, X_\tau = x_n\} &= \bbP\{X_{n + 1} = y_1, \dots, X_{n  + m} = y_m \mid X_0 = x_0, \dots, X_n = x_n\}\\
        &= \bbP\{X_{n + 1} = y_1, \dots, X_{n  + m} = y_m \mid X_n = x_n\}\\
        &= \bbP\{X_{1} = y_1, \dots, X_{ m} = y_m \mid X_0 = x_n\}
    \end{align*} and conclude with the regular Markov property and $n-$step invariance.
\end{proof}

\begin{exmp}
    Let $x\in S$ with $S$ finite and let $\tau = \min\{n \geq 0 \mid X_n = x\}.$ Assume that $\bbP\{\tau < \infty\} = 1.$ For any $x_0, \dots, x_n \in S$ such that 
    $\bbP\{X_0 = x_0, \dots, X_\tau = x_n\} >0,$ we have $x_n = x,$ and so the conditional distribution of $\{X_{\tau + j}\}_{j \geq 0}$ given everything up to $\tau$ is the same as the original chain starting at $x.$ 

    Thus, the Strong Markov property essentially guarantees that the Markov chain resets after hitting $\tau$!
\end{exmp}
    
\begin{defn}
    Let $X_n$ be a Markov chain on a countable state space $S.$ For any $x\in S,$ the \textbf{period} of $x$ is the greatest common divisor of $J_x = \{n \geq 1 \mid p^n(x,x) >0\}.$
\end{defn}
\begin{exmp}
    If $p(x,x) >0,$ then $1 \in J_x,$ and so the period of $x$ is $1.$
\end{exmp}

\begin{thm}
    If $x\leftrightarrow y,$ the periods of $x$ and $y,$ denoted by $d_x$ and $d_y$ respectively, are the same. 
\end{thm}
\begin{proof}
    Choose $n, m$ such that $p^n(x,y) >0$ and $p^m(y,x) >0.$ Then $p^{n +m}(x,x) >0$ and $p^{m + n}(y,y) >0.$ Thus, $ n + m \in J_x \cap J_y.$ Assume that $d_x < d_y.$ Then there exists some $k \in K_x$ not divisible by $d_y.$ Then $n + m + k \in J_y,$ and so $d_y$ divides $n + m + k$ and $n + m,$ and so $d_y$ divides $k,$ which is a contradiction.    
\end{proof}

\begin{defn}
    A Markov chain is aperiodic if every state has period $1.$
\end{defn}

\begin{exmp}
    A knight on an $8\times 8$ chessboard selects one of the next legal moves with equal probability, independently of the past. 
    \[S = \{(x,y) \in \bbR^2 \mid x \in \{1, \dots, 8\}, y \in \{1, \dots, 8\}\}.\]  The period is $2.$ 
\end{exmp}

\newpage
\subsection{Monday, Mar 31: Stationary Distributions}
\begin{defn}
    Let $\tilde{v} = (\tilde{v}_1, \tilde{v}_2, \dots, \tilde{v}_n)$ be a vector such that $\tilde{v}_j = \bbP\{X_0 = j\}.$ We say that $\tilde{v}$ is the \textbf{initial distribution} of the Markov chain.
\end{defn}
\begin{prop}
    For each $i \in [n],$ then $i$th entry of the row vector $\tilde{v} P$ is $\bbP\{X_1 = i\}.$
\end{prop}
\begin{exmp}
    Consider the Markov chain with $S = \{1,2,3,\}$ and 
    \[P = \begin{pmatrix}
        \frac{1}{2} & \frac{1}{4} & \frac{1}{4}\\
        \frac{1}{4} & \frac{1}{2} & \frac{1}{4}\\
        0 & \frac{1}{4} & \frac{3}{4}
    \end{pmatrix}\]
    For $n$ large, 
        \[P^n = \begin{pmatrix}
        \frac{1}{6} & \frac{1}{3} & \frac{1}{2}\\
        \frac{1}{6} & \frac{1}{3} & \frac{1}{2}\\
        \frac{1}{6} & \frac{1}{3} & \frac{1}{2}
    \end{pmatrix}.\] We encounter the phenomena that the limit of $P^n,$ if it exists, has identical rows. 

    Call this row $\pi.$ For any probability vector $\Tilde{v},$ $\lim_{n\to \infty} \Tilde{v} P^n = \pi$
\end{exmp}

Suppose $\pi$ is a limiting probability vector. That is, for any initial distribution $\Tilde{v},$ $\lim_{n\to \infty}\Tilde{v}P^n = \pi.$ Then 
\[\pi = \lim_{n\to \infty}\Tilde{v}P^{n + 1} = (\lim_{n\to \infty}\Tilde{v}P^n)P = \pi P\] We say that $\pi$ is a {stationary/invariant/equilibrium/steady-state} distribution for the Markov chain. 

\begin{defn}
    Let $\pi: S \to [0,1]$ be a probability distribution on $S$ such that $\sum_{x\in S} \pi_x = 1.$ We say that $\pi$ is a \textbf{stationary distribution} of $\{X_n\}$ if 
    \[\pi_y = \sum_{x\in S}\pi_x p(x,y), \quad \forall y \in S.\] That is, $\pi P =  \pi.$
\end{defn}

\begin{thm}
    If $S$ is finite and $\{X_n\}$ is an irreducible and aperiodic chain, then there exists a unique stationary distribution $\pi$ for $\{X_n\}.$ Moreover, for any $x,y \in S,$ \[\lim_{n\to \infty}p^n(y,x) = \pi_y\]
\end{thm}

\begin{proof}
    (Existence) Fix $z \in S.$ Suppose $X_0 = z.$ Let $\tau = \min\{n \geq 1 \mid X_n = z\}$ be the first return time to $z.$ Note that $\tau < \infty $ by proposition $4.$ For any $x\in S,$ define
    \[\Tilde{\pi}_x := \mathbb{E}[ \#\{n \in \{0,1, \dots \tau - 1\} \mid X_n = x\}]\] 
    We claim that 
    \[x \mapsto \frac{\pi_x}{\bbE[\tau]}\] is a stationary distribution for $\{X_n\}.$ We want to show that for all $y \in S,$ $\tilde{\pi}_y = \sum_{x\in S} \Tilde{\pi}_x p(x,y).$ Evidently, 
    \[\tilde{\pi}_x = \mathbb{E}\left[\sum_{x\in S}\mathbbm{1}_{\{X_n = x\}}\right] = \mathbb{E} \left[\sum_{n = 0}^\infty \mathbbm{1}_{\{X_n = x, \tau >n\}}\right] = \sum_{n =0}^\infty \bbP\{X_n = x, \tau >n\}.\] Thus, 
    \[\sum_{x\in S}\tilde{\pi}_x p(x,y) = \sum_{x\in S}\sum_{n = 0}^\infty \bbP\{X_n = x, \tau >n\} p(x,y) = \sum_{n = 0}^\infty \sum_{x\in S} \bbP\{X_n = x, T >n X_{n + 1}  = y\} = \sum_{n = 0}^\infty \bbP\{\tau >{n + 1}X_{n + 1} = y\} = \tilde{\pi}_y\]
    In order to find a stationary probability distribution, we need that 
    \[\sum_{x\in S} \frac{\tilde{\pi}_x}{\mathbb{E}[\tau]} = 1.\] But then 
    \[\tilde{pi}_x = \sum_{n = 0}^\infty \bbP\{X_n = x , \tau >n\} = \sum_{n = 0}^\infty \bbP\{\tau > n, X_n = x \mid X_n = x\}.\] So then 
    \[\tilde{\pi}_x  = \sum_{n  = 0}^\infty \sum_{x\in S}\bbP\{\tau > n  \mid X_n = x\}\bbP\{\tau  > n \mid X_n  = x\}\bbP\{X_n = x\} = \sum_{n = 0}^\infty \bbP\{\tau >n\} = \bbE[\tau]\]
\end{proof}

\begin{exmp}
    Consider a Markov chain $\{X_n\}$ with 
    \[P = \begin{pmatrix}
        \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
        \frac{1}{2} & 0 & \frac{1}{2}\\
        \frac{1}{5} & \frac{1}{5} & \frac{3}{5}
    \end{pmatrix}.\] $\{X_n\}$ is clearly aperiodic and irreducible. To compute $\pi,$ we solve the system $\pi P  = \pi,$ with $\pi_1 + \pi_2  + \pi_3 = 1.$ 
    \[(\pi_1 , \pi_2 ,\pi_3) P  = \pi \iff \frac{1}{3}\pi_1 + \frac{1}{2}\pi_2 + \frac{1}{5}\pi_3 = \pi_1,\quad  \frac{1}{3}\pi_1 + \frac{1}{5}\pi_3  = \pi_2, \quad  \frac{1}{3}\pi_1 + \frac{1}{2}\pi_2 + \frac{3}{5}\pi_3.\] Alternatively, we know that 
    \[\pi P = \pi \iff P^T \pi^T=\pi,\] and so we solve for the eigenvectors of $P^T$ corresponding to $\lambda = 1$ and then normalizing so that $\pi_1 + \pi_2 + \pi_3 = 1.$
    Solving, 
    \[\pi = (\frac{3}{10}, \frac{1}{5}, \frac{1}{2})\]
\end{exmp}


\newpage
\subsection{Wednesday, Apr 2: Uniqueness of Stationary Distributions}
\begin{thm}
    If $\pi$ is a stationary distribution for $\{X_n\},$ then for any $x,y \in S,$  then $\lim_{n\to \infty}\{\bbP\{X_n = y \mid X_0= x\}\} = \pi_y.$ Then $\pi$ is unique.
\end{thm}
\begin{proof}
    Let $\{X_n\}$ and $\{Y_n\}$ be two Markov chains starting at $x$ and $y,$ respectively. Consider the Markov chain $(X_n, Y_n)$ in $S\times S$ with transition probability \[\overline{p}((x,y), (x',y')) = \begin{cases}
        p(x,x')p(y,y'), \quad x\neq y\\
        p(x,x'), \qquad \qquad x' = y'\\
        0, \qquad \qquad \qquad \;\;x' \neq y'
    \end{cases}\]
    Note that $\bbP\{X_1 = x' \mid X_0 = x, Y_0 = y\} = \sum_{y \in S}p(x,x')p(y,y') = p(x,x').$ Then $\{X_n\}$ and $\{Y_n\}$ have the same as our original Markov chain. Let 
    \[\tau = \min\{n \mid X_n = Y_n\}.\] We claim that $\bbP\{\tau < \infty \mid X_0 = x, Y_0 = y\} = 1.$ We prove this on the homework. 

    Consider $(X_n, Y_n)$ where where $X_0 = x$ and $Y_0 = \pi,$ then $Y_n$ has distance $\pi$ for all $n,$ and for large $n,$ $X_n = Y_n.$ FOr any $y,$ 
    \[\lim_{n\to \infty}\bbP\{X_n = y \mid X_0 = x\} -\pi_ y = \lim_{n\to \infty}\left(\bbP\{X_n = y\} - \bbP\{Y_n - y\}\right) = 0.\]  Thus, if $\pi, \tilde{\pi}$ are two stationary distributions, then 
    \[\pi_y = \lim_{n\to \infty}\bbP\{X_n = y \mid X_0 = x\}= \tilde{\pi}_y\]
\end{proof}

\begin{prop}
    Let $\pi$ be a stationary distribution for $\{X_n\}$ and let $T_x:= \min\{n \geq 1 \mid X_n = x\}.$ Then 
    \[\pi_x = \frac{1}{\bbE[T_x \mid X_0 = x]}\]
\end{prop}
\begin{proof}
    Assume $X_0 =x.$ Then the stationary distribution is given by
    \[\pi_y = \frac{1}{\bbE[T_x]}\bbE[|\{n \in [T_x - 1] \mid X_n = y|].\] By definition, 
    \[|n \in \{0,1, \dots, T_x -1\}\mid X_n = x| = 1\] so then we are done.
\end{proof}

\begin{exmp}
    Let $G = (V,E)$ be a finite connected, non-bipartite graph. Then $\{X_n\}$ is irreducible and aperiodic. It is not hard to show that the sum of all the degrees is $2|E|$ since you need to count each edge twice. The stationary distribution for $\{X_n\}$ is 
    \[\pi_X = \frac{\deg x}{2|E|}.\] Note that $\pi$ is indeed a valid probability distribution since
    \[\sum_{x\in V} \pi_x = \sum_{x\in V}\frac{\deg x}{2 |E|} = \frac{2 |E|}{2 |E|} = 1.\] If $p(x,y) = \frac{1}{\deg x}$ and $x\sim y$ when they are joined by an edge and $0$ else, then for any $y \in V,$ 
    \[\sum_{x \in V}\pi_x p(x,y) = \sum_{x \mid x\sim y} \frac{1}{\deg x}\frac{\deg x}{ 2  |E|} = \frac{\deg y}{2 |E|} = \pi_y\]
\end{exmp}

\begin{exmp}
    Consider the Knight's Tour, where a knight chooses a legal move randomly on an $8 \times 8$ chessboard. What is expected time to return to the bottom left corner. The degrees are given by:
    \[\begin{bmatrix}
        2 & 3 & 4 & 4 & 4 & 4& 3 & 2\\
        3 & 4 & 6 & 6 & 6 & 6 & 4 & 3\\
        4 & 6 & 8 & 8 & 8 & 8 & 6 & 4\\
        \vdots\\
        2 & 3 & 4 & 4 & 4 & 4 & 3 & 2
    \end{bmatrix}\]
    Where the sum of degrees is $336,$ and so the expected time to return to $(1,1)$ is $\frac{336}{2}= 168.$
\end{exmp}

\begin{exmp}
    (King's) Tour
    \begin{exmp}
        \[\begin{bmatrix}
            3 & 5 & 5 & 5 & 5 & 5 & 5 & 3\\
            5 & 8 & 8 & 8 & 8 & 8 &8 &5\\
            \vdots\\
            3 & 5 & 5 & 5 & 5 & 5 & 5 & 3
        \end{bmatrix}\]
    \end{exmp}
    So then the expected number of moves till return is $140.$
\end{exmp}

\newpage
\subsection{Friday, Apr 4: First Step Analysis}
Our goal is to calculate the expected duration (that is, the hitting probability) conditioned on a first step. Let's illustrate using an example! Before, we do a little aside to talk about a useful technique that comes up naturally:
\begin{rem}
    Suppose $f$ satisfies
    \[f(n) = a f(n-1)+ bf(n+1), \qquad 0 \leq n \leq N,\] where $f(0)$ and $f(N)$ are known. Suppose $a\neq b$, then guess the solution to be 
    \[f(n) = \alpha^n,\] then 
    \[\alpha^n = a\alpha^{n-1} + b\alpha^{n+1} \implies \alpha = a + b\alpha^{2}\implies \alpha = \frac{1 \pm \sqrt{1 - 4ab}}{2b}.\] Thus the general solution is 
    \[f(n) = \lambda_1 \alpha_+^n + \lambda_2 \alpha_-^n\]
If $a = b,$ then 
\[f(n) = \lambda_1 n + \lambda_2,\] since we are left with a simple linear system.
\end{rem}
\begin{exmp}
    Consider the Gambler's Ruin where $S = \{0, 1,2, \dots, N-1, N\}$ with transition probabilities
    \[p(x, x+1) = p, \qquad p(x, x-1) = q, \quad x\notin \{0,N\}\]
    \[p(0,0) = p(N,N) = 1.\]
    That is, we have two absorbing boundaries and so we have three communication classes:
    \[C_1 = \{0\}, \quad C_2 = \{1,2,\dots, N-1\}, \quad C_3 = \{N\}.\] Note that $C_1$ and $C_3$ are recurring and $C_2$ is transient. Define
    \[\tau_k := \min\{n >0 : X_n\in C_1 \cup C_3 \mid X_0 = k\}, \quad P_k = \bbP\{X_{\tau_k} = N\}.\] We defined $P_k$ to be the probability that the gambler wins starting with $k$ dollars. Clearly, $P_0 = 0,$ $P_N = 1.$ Using the law of total probability
    \[P_k  =\bbP\{X_{\tau_k} = N\} = \bbP\{X_{\tau_k}  = N\mid X_1 = k+1\}\} \bbP\{X_1 = k+1\} + \bbP\{X_{\tau_k}  = N\mid X_1 = k-1\}\} \bbP\{X_1 = k-1\} = pP_{k+1} + qP_{k-1}.\]
    Using the above remark we see that 
    \[\alpha_+ = 1, \quad \alpha_- = \frac{1-p}{p}\]
    so 
    \[P_n = \lambda_1 + \lambda_2(\frac{1-p}{p})^n \implies P_0 = \lambda_1 + \lambda_2 = 0, \quad P_N = \lambda_1 + \lambda_2(\frac{1-p}{p})^N = 1\]
    Solving:
    \[P_n = \frac{1 - (\frac{1-p}{p})^n}{1 - (\frac{1-p}{p})^N}, \quad p \neq \frac{1}{2},\]
    \[P_n=  \frac{n}{N}, \quad p = \frac{1}{2}\]
\end{exmp}

\newpage
\subsection{Monday, Apr 7: Countable State Space}
Suppose the state space $S$ is countably infinite.
\begin{defn}
     We say a Markov Chain $\{X_n\}$ is \textbf{irreducible} if for all $x,y \in S,$ there exists some $n \in \bbN$ such that $p^n(x,y) >0$
\end{defn}
\begin{defn}
    We say $\{X_n\}$ is \textbf{recurrent} if 
    \[\bbP\{X_n = x \text{ i.o.}\mid X_0 = x\} = 1.\] We say $\{X_n\}$ is \textbf{transient} if it is not recurrent.
\end{defn}
\begin{prop}
    Suppose $\{X_n\}$ is irreducible. Then either every state is recurrent or every state is transient.
\end{prop}
\begin{proof}
    Suppose $x$ is a recurrent state. Without loss of generality, let $X_0 = x.$ Let $\tau_1, \tau_2,\dots$ be times to successive visits to $x.$ Note that $\tau_k < \infty$ since $x$ is recurrent. Note also that $\{X_{\tau_k}, \dots, X_{\tau_{k+1}}\}_{k\geq 0}$ are all i.i.d by the strong Markov property. Let $y \in S.$ There is some $n \in \bbN$ such that $p^n(x,y)>0$ by the irreducibility of $\{X_n\}.$ Thus, there is some $k$ such that \[q:=\bbP\{y \in \{X_{\tau_k}, \dots, X_{\tau_{k+1}}\}\}>0.\] Since the increments are identical, each increment has probability $q$ of containing $y.$ Thus, there is a probability $1$ that infinitely many of them contain $y.$ That is, if $\sigma = \min\{n\geq 0 \mid X_n = y\},$ then 
    \[\bbP\{\sigma < \infty \mid X_0 = x\} = 1.\] By the strong Markov property, $\{X_{\sigma + j}\}$ has the same distribution as $X_n$ started at $y.$ But we know that $\{X_{\sigma + j}\}$ visits $y$ infinitely many times starting at $x,$ and so $\{X_n\}$ will visit $y$ infinitely many times starting at $y.$
\end{proof}

\begin{prop}
    A state $x\in S$ is recurrent if and only if $\displaystyle\sum_{n=0}^\infty p^n(x,x)  = \infty.$
\end{prop}
\begin{proof}
We will prove the contrapositive of the forward direction.
    Define the total number of visits to $x$ by 
    \[R_x := \sum_{n=0}^\infty \mathbbm{1}_{X_n = x}.\] Then using linearity of expectation we fine that 
    \begin{align*}
        \bbE[R_x] &= \sum_{n=0}^\infty \bbE[\mathbbm{1}_{X_n = x}]\\
        &= \sum_{n=0}^\infty p^n(x,x)\\
        &< \infty.
    \end{align*}
   Since $\bbE[R_x] < \infty,$ then $R_x < \infty$ almost surely, and thus $x$ is transient.  

   Suppose $x$ is transient. Define $\tau_1, \tau_2, \dots$ as successive visits to $x.$ By transience, with probability $1,$ there is some $k$ such that $\tau_k = \infty.$ Let $q = \bbP\{\tau_k = \infty\}$ By the strong Markov property, $\tau_{k} - \tau_{k-1}$ are i.i.d. Thus, each increment has probability $q$ of being infinite. Then $R_x$ is the smallest $k$ such that $\tau_{k+1} = \infty.$ Then $R_x \sim \text{Geometric}(q)$ with the 'success' of $\tau_{k+1} = \infty.$ Thus, $\bbE[R_x] = \frac{1}{q}< \infty$ and we are done since 
   \[\sum_{n=0}^\infty p^n(x,x) = \bbE[R_x \mid X_0 = x] = \frac{1}{q} < \infty\]
\end{proof}
\begin{exmp}
    Consider the Markov Chain $\{X_n\}$ with $S = \{0,1,2,\dots\}.$ Then if the transition probabilities are given by 
    \[p(x,0) = \frac{1}{x + 2}, \quad p(x,x + 1) = 1 - \frac{1}{x + 2},\] we claim that $p^n$ is recurrent. To see this, it suffices to see that the series of $p^n(0,0)$ diverges. 
\end{exmp}


\newpage

\subsection{Wednesday, Apr 9: Queuing and Stationary Distributions for Countable State Spaces}
\begin{exmp}
    Let's continue the queue example from last class.
    
    Let $\{X_n\}$ be the number of people at time $n.$ Let $p \in (0,1)$ be the probability each person arrives and $q \in (0,1)$ be the probability each person leaves the queue. 
    
    If $p(0,1) = 0$ and $p(0,0) = 1-p$ and
    \[p(x,x-1) = q(1-p), \quad p(x,x+1) = p(1-q), \quad p(x,x) = pq + (1-q)(1-p).\] Thus, $p$ is probability a person enters the line and $q$ is the probability a person leaves (or is served). 
    \begin{prop}
        The queue is recurrent if and only if $q \geq p.$ 
    \end{prop}
    \begin{proof}
        Let $\tau_k$ be the $k$th time for which $X_n \neq X_{n-1}.$ For $x \geq 1,$ 
        \begin{align*}
        \bbP\{X_{\tau_k} = x + 1 \mid X_{\tau_{k-1}}= x\} &= \bbP\{X_{\tau_k} = x + 1 \mid X_{\tau_k -1} = x\}\\ &= \bbP\{X_1 = x + 1 \mid X_0 = x, X_1 \neq X_0\}\\ &= \frac{p(x,x+1)}{1 - p(x,x)}\\ &= \frac{p(1-q)}{q(1-p) + p(1-q)}    
        \end{align*}
        and by the same logic, 
        \[\bbP\{X_{\tau_k} = x-1 \mid X_{\tau_{k-1}} = x\} = 1- \frac{p(1-q)}{q(1-p) + p(1-q)}\]
        Thus, $\{X_{\tau_k}\}_{k\geq 0}$ is a biased random walk with parameter $\frac{p(1-q)}{q(1-p) + p(1-q)}.$ Thus, $\{X_{\tau_k}\}$ hits $0$ with probability 1 if and only if $\{X_n\}$ started from $x\geq 1$ hit $0$ with probability $1.$ From last class, happens if and only if 
        \[\frac{p(1-q)}{q(1-p) + p(1-q)} \leq \frac{1}{2} \iff p(1-q) \leq q(1-p) \iff p \leq q\]
    \end{proof}
\end{exmp}

\begin{rem}
    By the Brower fixed point theorem, we have the existence of a stationary distribution in finite space spaces. 
\end{rem}

Recall that if $S$ is finite, then for an irreducible, aperiodic Markov chain, there exists a unique stationary distribution $\pi$ that satisfies 
\[\sum_{x\ in S} \pi_x = 1 , \qquad \pi P = \pi \iff \sum_{x\in S} \pi_x p(x,y) = \pi_y.\]

In the countably infinite space, we note that a transient state space cannot yield a stationary distribution since the expected return times are all $\infty.$
\begin{defn}
    Suppose $\{X_n\}$ is irreducible and recurrent. We say that $\{X_n\}$ is \textbf{null recurrent} if 
    \[\lim_{n\to \infty}p^n(x,y)= 0, \quad \forall\; x,y \in S.\] Otherwise, $\{X_n\}$ is \textbf{positive recurrent}.
\end{defn}
\begin{rem}
    Clearly, null recurrent Markov chains also have infinite return times, and thus have no stationary distribution.
\end{rem}
\begin{prop}
    Suppose $\{X_n\}$ is irreducible. The following are equivalent:
    \begin{enumerate}
        \item $\{X_n\}$ is positive recurrent;
        \item $\{X_n\}$ has a stationary distribution;
        \item For any $x,y \in S,$ 
        \[\limsup_{n\to \infty} p^n(x,y) > 0.\]
        \item If $T_x = \min\{n \geq 1 \mid X_n = x\},$ then 
        \[\bbE[T_x \mid X_0 = x] < \infty\] for any $x \in S.$
    \end{enumerate}
    Furthermore, if $\{X_n\}$ is aperiodic and positive recurrent, then $\pi$ is unique and for any $x\in S,$
    \[\pi_x = \frac{1}{\bbE[T_x \mid X_0 = x]}\]
\end{prop}

\begin{rem}
    By condition 3, checking that a recurrent Markov chain is null recurrent amount to checking that $\lim_{n\to \infty}p^n(x,y) = 0$ for some states $x,y \in S.$
\end{rem}
\begin{exmp}
    Consider the biased random walk on $\{0,1, \dots\}$ with partially reflecting boundary: 
    \[p(x,x-1) = q= 1-p, \quad p(x,x+1) = p, \quad p(0,0) = q, \quad p(0,1) =p.\]
    Is this positive recurrent?

    We know that $\{X_n\}$ is transient for $p > \frac{1}{2}.$ For some $\pi$ to possibly exist, we need $p < \frac{1}{2}.$ The stationary distribution must satisfy:
    \[\pi(x) = p\pi(x-1) + q\pi(x+1), \quad \forall x\geq 1.\] Moreover, 
    \[\pi(0) = q\pi(0) + q\pi(1).\] This is because 
    \[\pi P = \pi \begin{pmatrix}
        q & p & 0 & 0 & \cdots\\
        q & 0 & p & 0 & \cdots \\
        0 & q & 0 & p& \cdots\\
        \vdots&\vdots& \vdots & \vdots &\ddots
    \end{pmatrix} = \begin{pmatrix}
        \pi_0\\ \pi_1 \\
        \vdots
    \end{pmatrix}\] For $p < \frac{1}{2},$ the solution takes the form 
    \[\pi(x) = \lambda_1 + \lambda_2 (\frac{p}{1-p})^x\] We need 
    \[\sum_{x = 0}^\infty \pi(x) = 1 \implies \lambda_1 = 0.\] After some algebra, we find that $\lambda_1 = 1- \frac{p}{1-p},$ and thus 
    \[\pi(x) = (1- \frac{p}{1-p})(\frac{p}{1-p})^x.\] Thus, for $p< \frac{1}{2},$ $\{X_n\}$ is positive recurrent. 
    
    For $p = \frac{1}{2},$ the general solution is 
    \[\pi(x) = \lambda_1 + \lambda_2 x.\] But
    \[\sum_{n=0}^\infty \pi(x) < \infty \implies \lambda_1 = \lambda_2 = 0,\] and thus $\{X_n\}$ is null recurrent. 
\end{exmp}

\newpage
\subsection{Friday, Apr 11: Random Walks on $\bbZ^d$}
Consider $\bbZ^d$ as a graph with edges joining each $x,y \in \bbZ^d$ such that $\|z-y\|_1 = 1.$ Then the random walk $\bbZ^d$ is a Markov chain moving distance $1$ in any of the $2d$ possible directions at each step.
\begin{rem}
    (Stirling's Approximation) For $n$ large, 
    \[n! \sim \sqrt{2\pi n}(\frac{n}{e})^n\]
\end{rem}
\begin{prop}
    The random walk is recurrent for $d = 1,2$ and transient for $d\geq 3$
\end{prop}
\begin{proof}
    For $d = 1,$ we can graph the random walk by every time we go to the right, we take a step up, and every time we go left, we take a step down. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Images/Drunkard's Walk.png}
    \caption{From My REU Paper}
\end{figure}
We wish to show that $\sum_{n=1}^\infty p^n(0,0) = \infty.$ Since the parity of $n$ must be even, it suffices to show that $\sum_{n=1}^\infty p^{2n}(0,0).$ After a bit of thought, and by using Stirling's Formula above,
\[p^{2n}(0,0) = \bbP\{X_{2n} = 0 \mid X_0 = 0\} = \frac{\binom{2n}{n}}{2^{2n}} \sim \frac{\sqrt{4\pi n}(\frac{2n}{e})^{2n}}{2\pi n (\frac{n}{e})^{2n}}2^{-2n} = \frac{1}{\sqrt{\pi n}}.\] Hence, the infinite series diverges and so the random walk on $\bbZ$ is recurrent. Indeed, it is null recurrent. 

For $d = 2,$ we want to do something similar. Fix $j.$ There must be $j$ steps to the right and $j$ steps to the left in order to get back to the origin. Thus, there must be $n-j$ steps up and $n-j$ steps down. Thus, there are 
\[\frac{2n!}{j!^2(n-j)!^2}\] of such combinations.
\[p^{2n}(0,0) = \frac{\sum_{j=0}^{n}\frac{(2n)!}{(j!)^2 (n-j)!^2}}{4^{2n}} = \frac{1}{4^{2n}}\frac{(2n)!}{n!^2}\sum_{j=0}^n \left(\frac{n!}{j! (n-j)!}\right)^2 = \frac{1}{4^{2n}}\binom{2n}{n}\sum_{j=0}^n \binom{n }{j}\binom{n}{n-j} = \frac{1}{4^{2n}} \binom{2n}{n}^2\] By Stirling's approximation,
\[p^{2n}(0,0)   = \frac{1}{4^{2n}} \binom{2n}{n}^2\approx \frac{1}{\pi n} \implies \sum_{n=0}^\infty p^{2n}(0,0) = \infty,\] and thus the random walk is null recurrent.


For $d\geq 3,$ it can be shown that $p^{2n} = \left(\frac{1}{\sqrt{\frac{2\pi n}{d}}}\right)^d$

\end{proof}


\newpage
\subsection{Monday, Apr 14: Branching Processes}
Let $\{X_n\}$ denote the size of the population at time $n.$ Independent of the rest, each individual produces some number of offspring according to an offspring distribution $\{p_k\}.$ We remark that 
$\{p_k\}_{k\geq 0}$ satisfies $p_k \geq 0$ for all $k$ and $\sum_{k=0}^\infty p_k = 1.$ Informally, $p_k$ represents the probability of an individual producing $k$ children. Then if each $n$ represents a new generation where each previous generation dies of, then 
\[X_{n+1} = \sum_{j=1}^{X_n} \xi_j,\] where the $\xi_j$ are conditionally independent given $X_n$ with 
\[\bbP\{\xi_j  =k \mid X_n = x\} = p_k.\] Thus, $\xi_j$ is how many offspring individual $j$ produces. We are interested in the extinction probability, which is formally denoted by 
\[a:= \bbP\{\exists n\geq 1 \text{ s.t. } X_n = 0 \mid X_0 = 1\}.\] Denote the mean of the offspring distribution of each individual by 
\[\mu:= \sum_{k=0}^\infty kp_k.\] Note that 
\[\bbE[X_{n+1} \mid X_n = m] = \sum_{j=1}^m \bbE[\xi_j] = \mu m.\] Then using the law of total expectation, \[\bbE[X_{n+1}] = \sum_{m=0}^\infty\bbE[X_{n+1} \mid X_n]\bbP\{X_n = m\} = \mu \sum_{m=0}^\infty m\bbP\{X_n = m\} = \mu \bbE[X_n],\] and so $\bbE[X_n] = \mu^n \bbE[X_0].$

\begin{prop}
    If $\mu < 1,$ then $a = 1.$ 
\end{prop}
\begin{proof}
    Since $\bbE[X_n] \leq \mu^n \to 0$ as $n\to \infty,$ then $\bbE[X_n] \to 0.$ Consider that by Markov's inequality
    \[\bbP\{X_n \neq 0\} = \bbP\{X_n \geq 1\} \leq \bbE[X_n]\to 0,\] and so $\bbP\{X_n = 0\} \to 1$ as $n\to \infty.$ 
\end{proof}

\begin{rem}
    If $X_1 = k,$ then by independence, $\bbP\{\text{extinction} \mid X_1 = k\} = a^k.$ Thus, 
    \[a = \bbP\{\text{extinction} \mid X_0 = 1\} = \sum_{k=0}^\infty \bbP\{X_1 = k\}\bbP\{\text{extinction} \mid X_1 = k\} = \sum_{k=0}^\infty p_k a^k.\]
\end{rem}

\begin{defn}
    Let $Y$ be a random variable taking values in $\{0,1,2,\dots\}.$ Then the \textbf{generating function} for $Y$ is given by 
    \[\phi : [0, \infty) \to [0,\infty), \quad \phi(s) = \phi_Y(s) = \bbE[s^y] := \sum_{k=0}^\infty \bbP\{Y = k\}s^k\]
\end{defn}
\begin{rem}
    (Basic Properties of $\phi$):
    \begin{enumerate}
        \item We allow $\phi(s) = \infty,$ but we have that $\phi(s) < \infty$ for $s\in [0,1]$ since it is bounded above by a converging geometric series. 
        \item $\phi (1) = 1$ and $\phi(0) = p_0.$ 
        \item The derivative has meaning:
        \[\phi'(s) = \sum_{k=1}^\infty \bbP\{Y = k\} k s^{k-1} \implies \phi'(1) = \bbE[Y].\]
        \item If $Y_1, \dots Y_m$ are independent random variables, then 
        \[\phi_{Y_1 + \dots + Y_m}(s) = \bbE[S^{Y_1 + \dots + Y_m}] = \prod_{j=1}^m \phi_{Y_j}(s)\]
    \end{enumerate}
    \end{rem}

\begin{prop}
    Let $\phi$ be the generating function for $p_k.$ Let $\phi^{(n)} = \phi \circ \phi \dots \circ \phi$ ($n$ times). Then
    \[\phi_{X_n}(s) = \phi^{(n)}(s)\]
\end{prop}
\begin{proof}
    It suffices to show that $\phi_{X_{n+1}}(s) = \phi_{X_{n}}(\phi(s)).$ By definition, 
    \begin{align*}
        \phi_{X_{n+1}}(s) &= \sum_{k=0}^\infty \bbP\{X_{n+1} = k\}s^k\\
        &= \sum_{k=0}^\infty \sum_{j=0}^\infty \bbP\{X_{n+1} = k \mid X_n = j\}\bbP\{X_n = j\} s^k\\
        &= \sum_{j=0}^\infty \bbP\{X_n = j\}\sum_{k=0}^\infty \bbP\{X_{n+1} = k \mid X_n = j\}s^k\\
        &= \sum_{j=0}^\infty \bbP\{X_n = j\} \phi(s)^j\\
        &= \sum_{j=0}^\infty \bbP\{X_n = j\} \phi(s)^j\\
        &= \phi_{X_n}(\phi(s))
    \end{align*}
\end{proof}

\newpage
\subsection{Wednesday, Apr 16: Extinction Probabilities}
Recall the generating function 
\[\phi_X (s) = \sum_{k=0}^\infty p_k s^k\]
\begin{prop}
    The extinction probability is the smallest positive solution for which $\phi(s) = s$ given that $0 < p_0 < 1.$
\end{prop}
\begin{proof}
    Since the set $\{s: \phi(s) = s\}$ is closed by continuity, then since $p_0 = \phi(0) = 0,$ then $0 \notin S.$ Thus, the set has a smallest positive element $s_0.$ Since $\phi(1) = 1,$ then $s_0 \leq 1.$ We claim that 
    \[\phi_{X_n}(0) < s_0,\quad  n\geq 0\] This is clear for $n=0$ since $\phi_{X_0}(0) = 0.$ If this is true for $n,$ that $\phi_{X_n}(0) < s_0,$ then by our proposition 14, and the fact that $\phi$ is strictly increasing (the derivative is strictly increasing) we have that 
    \[\phi_{X_{n+1}}(0) = \phi(\phi_{X_n}(0)) < \phi(s_0) = s_0.\] Note that since $\phi_{X_n}(0) = \bbP\{X_n = 0\},$ then 
    \[a = \lim_{n\to \infty}\phi_{X_n}(0) \leq s_0.\] Since $\phi(a) = a,$ then $a = s_0.$
\end{proof}
\begin{prop}
    If $\mu >1,$ then $a<1.$ If $\mu \leq 1$ and $p_0 \neq 0,$ then $a = 1.$ In particular, the population will die with probability $1$ if, and only if, $\mu \leq 1$ and $p_0 \neq 0.$
\end{prop}
\begin{proof}
    Suppose $\mu = 1$ and $p_0 \neq 0.$ Note that 
    \[\phi''(s) = \sum_{k=2}^\infty k(k-1)p_k s^{k-2}.\] If $p_0 \neq 0$ and $\mu = 1,$ then we claim that $p_k >0$ for some $k \geq 2.$ If not, then $\mu = p_1 < 1.$ Then $\phi''(s) >0.$ Recall that $\phi(1) = 1$ and $\phi'(1) = \mu.$ Thus, $\phi'(s) < \mu$ for all $s\in [0,1).$ If $\mu = 1,$ then 
    \[1 - \phi(s) = \int_s^1 \phi'(t)dt < \int_s^1 \mu dt  = 1-s.\] Thus, $\phi(s) >s$ for all $s\in [0,1).$ Thus, $a = 1. $ 

    If $\mu >1,$ then $\phi'(1) >1,$ $\phi(1) = 1.$ Then there exists $s<1$ such that $\phi(s) < s.$ Since $\phi(0) >0,$ the continuity of $t \mapsto \phi(t)-t$ implies by the IVT there is a $t\in (0,1)$ such that $\phi(t) = t.$ Hence, $a<1. $
\end{proof}

\begin{defn}
    We say that a branching process is \textbf{subcritical} if $\mu <1,$ \textbf{critical} if $\mu  = 1,$ and \textbf{supercritical} if $\mu >1.$ 
\end{defn}

\begin{exmp}
    Suppose $p_0 = \frac{1}{10},$ $p_1 = \frac{3}{5},$ and $p_2 = \frac{3}{10},$ then 
    \[\mu = \frac{1}{10} + \frac{3}{5} + \frac{6}{10} = \frac{12}{10} >1.\] Note that 
    \[\phi(s) = \sum_{k=0}^3 p_ks^k = \frac{1}{10} + \frac{3}{5}s + \frac{3}{10}s^2.\] We want the smallest positive solution to $\phi(s) = s.$ Solving gives $ a = \frac{1}{3}. $
\end{exmp}

\begin{exmp}
    Bacteria reproduce by cell division. In one unit of time, bacterium will either die (w.p. $\frac{1}{4}$,) stay the same (w.p. $\frac{1}{4}$), or split in 2 (w.p. $\frac{1}{2}$). At time $n = 0,$ the population starts with $100$ bacteria. 

    We can interpret this as the following: If a bacteria dies, then it produces three offspring?
    Then 
    \[\phi(s) = \sum_{k = 0}^\infty p_k s^k,\] where 
    \[p_1 = \frac{1}{4}, p_2  = \frac{1}{4}, p_3 = \frac{1}{2}\]
    \[\phi(s)= \frac{1}{4} + \frac{1}{4}s + \frac{1}{2} s^2, \quad Y_1, \dots, Y_{100}, \quad \phi_{Y_1 + \cdots Y_{100}} = (\tilde{\phi})^{100}.\] Then 
    \[\mu = \frac{1}{4} + 1 >1.\] Thus, we need to solve 
    \[\phi(s) - s = 0 \implies s = \frac{1}{2}\] for each one. Thus, by independence,
    \[ a = \frac{1}{2^{100}}\]
\end{exmp}
\newpage

\subsection{Friday, Apr 18: Poisson Processes}

\begin{defn}
    A random variable $Y$ is \textbf{Poisson} with parameter $\lambda$ if for all $k\geq 0,$ we have that 
    \[\bbP\{Y  = k\} = e^{-\lambda}\frac{\lambda^k}{k!}\]
\end{defn}
\begin{rem}
    Recall that $\bbE[Y] = \Var[Y] = \lambda.$ 
\end{rem}
\begin{prop}
    Suppose $Y_1,Y_2$ are independent Poisson random variables with parameters $\lambda_1, \lambda_2,$ respectively. Then $Y_1 + Y_2 \sim \text{Poisson}(\lambda_1 + \lambda_2).$
\end{prop}

We motivate the Poisson process with an example:
\begin{exmp}
    Suppose that in a phone line, calls occur at the same rate $\lambda$ at all hours in a day. The number of calls during disjoint time intervals are independent. Let $X_t$ be the number of calls at (or before) time $t.$  
\end{exmp}

\begin{defn}
    The \textbf{Poisson process} with rate $\lambda$ is the continuous time stochastic process $\{X_t\}_{t\geq 0}$ such that:
    \begin{itemize}
        \item $X_0 = 0;$
        \item For any times $0 \leq s_1 \leq t_1 \leq s_2 \leq \cdots \leq s_k \leq t_k,$ the random increments 
        \[X_{t_j} - X_{s_j} \sim \text{Poisson}(\lambda (t_j - s_j))\] are independent
    \end{itemize}
\end{defn}

\begin{defn}
    A random variable $T \in [0, \infty)$ has the exponential distribution with parameter $\lambda$ if 
    \[\bbP\{T \geq t\} = e^{-\lambda}\]
\end{defn}
Recall that $\bbE[T] = \frac{1}{\lambda}$ and $\Var[T] = \frac{1}{\lambda^2}.$

\begin{rem}
    We could alternatively describe a Poisson process in terms of arrival times. Let $\tau_0 = 0$ and let $\tau_j = \inf\{t \geq 0 \mid X_t = j\}$ be the time of the $j$th call. Then $X_t = \max\{j \mid \tau_j \leq t\}$ is the number of calls before time $t.$ 
\end{rem}

\begin{prop}
    The arrival times $\tau_j - \tau_{j-1}$ for $j = 1,2,3,\dots$ are i.i.d. and each has exponential distribution with parameter $\lambda.$
\end{prop}
\begin{proof}
    Note that $\tau_0 = 0,$ and 
    \begin{align*}
        \bbP\{\tau_1 > t\} = \bbP\{X_t = 0\} = \frac{e^{-\lambda }\lambda^k}{k!} = e^{-\lambda}.
    \end{align*}
    Then $\tau_1 \sim \text{Exp}(\lambda).$ Note that $\tau_1$ is a stopping time for $\{X_t\}$ and $\{T_{s + t} - X_t\}_{s\geq0}$ is a Poisson process independent of $\{X_s\}_{s\leq t}.$ By the strong Markov property, 
    \[\{X_{s + \tau_1} - X_{\tau_1}\}_{s\geq 0}\] is Poisson and independent of $\{X_{s}\}_{s\leq \tau_1}.$ In particular, $\tau_2 - \tau_1$ is independent of $\tau_1$ and has the same distribution.
\end{proof}

\begin{exmp}
    Suppose $\{X_t\}_{t\geq 0}$ is a Poisson process with rate $\lambda.$ Then 
    \[\bbE[X_2 \mid X_1] = X_1 + \lambda\]
\end{exmp}

\newpage
\subsection{Monday, Apr 21: Continuous Time Markov Process}
\begin{prop}
    (Minimum Property) Suppose $T_1, \dots, T_n$ are independent exponential r.v. with parameters $\lambda_1, \dots, \lambda_n$ (respectively). Then $\min\{T_1, \dots, T_n\}$ is an exponential random variable with parameter $\lambda_1 + \cdots + \lambda_n.$ Moreover, for any $j  = 1,2,3\dots, n,$ we have that
    \[\bbP\{T_j = \min\{T_1, \dots, T_n\}\} = \frac{\lambda_j}{\lambda_1 + \dots + \lambda_n}\]
\end{prop} 
\begin{proof}
    We have that 
    \begin{align*}
        \bbP\{T_{(1)}\geq t\} &= \bbP\{T_1, \geq t, T_2 \geq t, \dots , T_n \geq t\}\\
        &= \bbP\{T_1 \geq t\}\cdots \bbP\{T_n \geq t\}\\
        &= e^{-\lambda_1 t}\cdots e^{-\lambda_n t}\\
        &= e^{-(\lambda_1 + \cdots + \lambda_n)t}.
    \end{align*}
    For the second claim, we have that if $j=1,$ then 
    \begin{align*}
        \bbP\{T_1 = T_{(1)}\} &= \bbP\{T_j \geq T_1, \;\forall j = 1,2,\dots, n\}\\
        &= \bbE[\bbP\{T_j \geq T_1, \;\forall j = 1,2,\dots, n \mid T_1\}]\\
        &=  \bbE[e^{-(\lambda_1 + \dots, \lambda_n)T_1}]\\
        &= \lambda_1\int_{0}^\infty e^{-(\lambda_1 + \dots, \lambda_n)t}dt\\
        &= \frac{\lambda_1}{\sum_{j=1}^n\lambda_j}
    \end{align*}
    
\end{proof}

Suppose $S$ is a finite state space. We wish to define a stochastic process $\{X_t\}_{t\geq 0}$ taking values in $x.$ For distinct $x,y \in S,$ there exists some rates $\alpha(x,y) \geq 0 $ that specify how frequently we jump from $x$ to $y$.
\begin{rem}
    For $y \in S$ with $\alpha(x,y) \neq 0,$ let $T_1$ be an exponential r.v. with parameter $\alpha(x,y).$  Let $T = \min_y T_y.$ By the minimum property, $T\sim \exp(\alpha(x)),$ where $\alpha(x) = \sum_{y \in S\sm \{x\}}\alpha(x,y).$ Moreover, we have that 
    \[\bbP\{X_T = y\} = \frac{\alpha(x,y)}{\alpha(x)}\]
\end{rem}

\begin{prop}
(The Markov Property)
    Let $t \geq 0$ and $x\in S.$ The conditional distribution of $\{X_{t + s}\}_{s\geq 0 }$ given $\{X_t = x\}$ (and everything before time $t$), is the same as the distribution of $\{X_s\}$ started from $x.$ 
\end{prop}

Now, we aim to write down a transition matrix for this process. 
\begin{defn}
    Define the \textbf{$t-$time transition probabilities} to be 
    \[p_t(x,y) = \bbP\{X_t = y  \mid X_0 = x\}\] and label $S = \{1,2,\dots, N\}$ and define the \textbf{$t-$time transition matrix} as 
    \[P_t = \begin{pmatrix}
        p_t(x,y)
    \end{pmatrix}_{x,y = 1,2,\dots, N}\]
\end{defn}
\begin{rem}
For $x\neq y,$ we know that by the Markov Property, 
\[\bbP\{X_{t  + \epsilon} = y \mid X_t = x\} = \bbP\{X_\epsilon = y \mid X_0 = x\} \approx \bbP\{T_y < \epsilon\} = 1 - e^{\alpha(x,y)\epsilon}  = \alpha(x,y)\epsilon + O(\epsilon^2).\] Thus, 
\[\bbP\{X_{t + \epsilon} \neq x \mid X_t = x\} = \sum_{y \sm \{x\}}\alpha(x,y)\epsilon  + O(\epsilon^2) = \alpha(x)\epsilon + O(\epsilon^2).\]

Informally, \[\frac{d}{dt}p_t(x,y) = \lim_{\epsilon \to 0} \frac{1}{\epsilon}\left(\bbP\{X_{t + \epsilon }  = y \mid X_0 = x\} - \bbP\{X_t = y \mid X_0 = x\}\right) = \cdots = \sum_{z\in S\sm \{y\}}\alpha(x,y)p_t(x,z) - \alpha(y)p_t(x,y)\]

In matrix form, 
\[\frac{d}{dt}P_t = P_tA,\] where $A$ is the $N\times N$ whose $x,y$ entry is $\alpha(x,y)$ if $x\neq y$ and $-\alpha(x)$ if $x = y.$ Note that $p_0 (x,x) = 1$ and $p_0(x,y) =0.$ Thus, $P_0 = I.$ The solution to this ODE gives 
\[P_t = e^{tA}\]

\end{rem}

\newpage
\subsection{Wednesday, Apr 23: Midterm}



\newpage
\subsection{Friday, Apr 25: $t-$Time Transition Matrix}
\begin{rem}
    Since $P_t = e^{tA},$ we have that 
    \[e^{tA} = \sum_{n=0}^\infty \frac{(tA)^n}{n!}.\] Thus, if $A = QDQ^{-1}$ and so 
    \[e^{tA} = Q e^{tD}Q^{-1}.\] Note that if $D$ is diagonal with entries $\lambda_1, \dots, \lambda_m,$ then $e^{tD}$ is the diagonal matrix with diagonal entries $e^{t\lambda_1}, \dots, e^{t\lambda_m}.$

    The matrix $A$ is called the \textbf{infinitesimal generator} for the Markov Chain.
\end{rem}

\begin{exmp}
    Consider the Markov Chain with state space $S = \{0,1\}$ and rates 
    \[\alpha(0,1) = 2, \quad \alpha(1,0) = 3.\]
    Then 
    \[A = \begin{pmatrix}
        -2 & 2\\
        3 & -3
    \end{pmatrix}\] Then 
    \[A - \lambda I =  \begin{pmatrix}
        -2 - \lambda & 2  \\
        3   & -3 - \lambda
    \end{pmatrix}\] Then 
    \[|A - \lambda I | = (-2 - \lambda)(-3 - \lambda) - 6 \implies \lambda_1 = -5, \lambda_2 = 0.\] Then finding the null space $E_{-5}$ is 
    \[E_{-5} = \{v \mid (A - \lambda_{-5})v = 0\}\] which is formed by $v_5= (-2,3).$ Similarly, $v_0 = (1,1).$ Thus, 
    \[D = \begin{pmatrix}
        -5 & 0\\
        0 & 0
    \end{pmatrix}\quad Q = \begin{pmatrix}
        -2 & 1 \\
        -3 & 1
    \end{pmatrix} \quad Q^{-1} = \] and so 
    \[P_t = QDQ^{-1}= \begin{pmatrix}
        -2 & 1 \\
        -3 & 1
    \end{pmatrix} \begin{pmatrix}
        e^{-5t} & 0\\
        0 & 1
    \end{pmatrix}\begin{pmatrix}
        -2 & 1 \\
        -3 & 1
    \end{pmatrix}^{-1} = \frac{1}{5}\begin{pmatrix}
        3 + 2e^{-5t} & 2- 2e^{-5t}\\
        3 - 3e^{-5t} & 2 + 3e^{-5t}
    \end{pmatrix}\]
    Then 
    \[\bbP\{X_1 = 1 \mid X_0 = 0\} = \frac{2 - 2e^{-5t}}{5}\]
\end{exmp}

\begin{defn}
    A continuous time Markov Chain is \textbf{irreducible} if $p_t(x,y) >0$ for all $x,y \in S.$ and for all $t>0.$
\end{defn}
\begin{defn}
    A function $\pi: S \to [0,1]$ with $\sum_{x \in S}\pi_x = 1$ is an \textbf{invariant/stationary distribution} for $\{X_t\}$ if the following is true:
    \begin{itemize}
        \item If $X_0$ has distribution $\pi,$ then $X_t$ has distribution $\pi$ for all $t\geq 0.$
        \item It satisfies \[\frac{d}{dt}\pi P_t = 0 \iff \frac{d}{dt}\pi e^{tA} = 0 \iff \pi A = 0.\]
    \end{itemize}
\end{defn}

\begin{prop}
    If $\{X_t\}$ is irreducible, then there exists a unique stationary distribution $\pi$ for $\{X_t\}$ which satisfies, for any $x,y \in S,$
    \[\lim_{t\to \infty} p_t(x,y) = \pi_y\]
\end{prop}
\begin{exmp}
    It is easy to see that in the example above, 
    \[\pi = \begin{pmatrix}
        \frac{3}{5} & \frac{2}{5}
    \end{pmatrix}\]
\end{exmp}

\newpage
\subsection{Monday, Apr 28: Conditional Expectation}

\begin{rem}
    Suppose $X$ and $Y$ are r.v. taking values in countable sets $S,T \subset \bbR.$ For $x \in S$ and $y \in T,$ let 
    \[f(x,y) = \bbP\{X = x, Y = y\}.\] Then the \textit{conditional expectation} is 
    \[\bbE[X \mid Y = y] = \sum_{x \in S}x \bbP\{X = x \mid Y = y\} = \frac{\displaystyle\sum_{x\in S}s f(x,y)}{\displaystyle\sum_{x\in S}f(x,y)}.\] Moreover, we define the random variable
    \[\bbE[X \mid Y] = \frac{\displaystyle\sum_{x \in S} xf(x,y)}{\displaystyle\sum_{x\in S}f(x,y)}\]
\end{rem}

\begin{defn}
    Let $X,Y$ be random variables with $X$ taking values in $\bbR$ and with $\bbE[ | X|] < \infty.$ The \textbf{conditional expectation} $\bbE[X \mid Y]$ is the unique random variable  that satisfies the following:
    \begin{enumerate}
        \item $\bbE[X \mid Y]$ is a function of $Y.$
        \item If $F(y)$ is a function of $y$ taking values in $\bbR$ and $\bbE[ |F(y) | ] < \infty,$ then 
        \[\bbE[X \, F(Y)] = \bbE[\bbE[X \mid Y]  F(Y)]\]
    \end{enumerate}
\end{defn}

Suppose $\bbE[|X|] < \infty$ for any random variable talked about in this class.
\begin{defn}
 Let $\{X_t\}_{tâT}$ be a stochastic process. We say that the \textbf{natural filtration} of $X_t$ is the sigma algebra generated by $Y_t$. That is,
 $\mathcal{F}_t =\sigma(Y_1,Y_2,...,Y_t)$.
\end{defn}
We note that the natural filtration of $X_0, \dots, X_n$ is the information contained in these random variables. 
\begin{rem}
    Moreover, 
    \[\bbE[X \mid \mathcal{F}_n] = \bbE[Y_0, \dots, Y_n]\]
 and we say that $X$ is $\mathcal{F}_n-$measurable if it is a function of $Y_0, \dots, Y_n$
 \end{rem}
 \begin{prop}
     $\bbE[X \mid \mathcal{F}_n]$ is the unique real valued random variable satisfying the following:
     \begin{enumerate}
         \item $\bbE[X \mid \mathcal{F}_n]$ is $\mathcal{F}_n$ measurable.
         \item $\bbE[X  Z] = \bbE[\bbE[X \mid \mathcal{F}_n]  Z]$
     \end{enumerate}
 \end{prop}

\begin{prop}(Linearity) Suppose $X_1, X_2$ are real valued r.v.s and $a,b \in \bbR.$ Then 
\[\bbE[aX_1 + bX_2 \mid \mathcal{F}_n] =  a\bbE[X _1 \mid \mathcal{F}_n] +  b\bbE[ X_2 | \mathcal{F}_n]\]
\end{prop}
\begin{proof}
    If $Z$ is $\mathcal{F}_n-$measurable, then  $\bbE[(aX_1 + bX_2 ) Z] = \bbE[\bbE[aX_1 + bX_2 \mid \mathcal{F}_n] Z].$ Let
    \[W:= a\bbE[X_1 \mid \mathcal{F}_n] + b\bbE[X_2 \mid \mathcal{F}_n]\] Then 
    \begin{align*}
        \bbE[W Z] &= \bbE[(a \bbE[X_1 \mid \mathcal{F}_n] + b\bbE[X_2 \mid \mathcal{F}_n])  Z]\\
        &= \bbE[a \bbE[X_1 \mid \mathcal{F}_n] Z] + \bbE[b\bbE[X_2 \mid \mathcal{F}_n] Z]\\
        &= a\bbE[X_1  Z] + b\bbE[X_2  Z]\\
        &= \bbE[(aX_1 + bX_2)  Z].
    \end{align*}
    Because conditional expectation is unique, we are done.
\end{proof}
\begin{prop}
    Suppose $X$ is $\mathcal{F}_n-$measurable, then $\bbE[X \mid \mathcal{F}_n] = X.$
\end{prop}
\begin{prop}
    If $X$ is independent from $\mathcal{F}_n,$ then 
    \[\bbE[X \mid \mathcal{F}_n] = \bbE[X]\]
\end{prop}
\begin{prop}
    If $Z$ is $\mathcal{F}_n-$measurable, then 
    $\bbE[ZX \mid \mathcal{F}_n] = Z\bbE[X \mid \mathcal{F}_n].$
\end{prop}
\begin{prop}
    If $m\leq n,$ then 
    \[\bbE[\bbE[X \mid \mathcal{F}_n] \mid \mathcal{F}_m]= \bbE[X \mid \mathcal{F}_m]\]
\end{prop}
\begin{exmp}
    Let $X_1, X_2,\dots$ be i.i.d r.vs with mean $\mu.$ Then if $m\geq n,$ 
    \[\bbE[X_1  + \dots  + X_n \mid \mathcal{F}_m] = X_1 + \dots + 
 X_n.\] If $m < n,$ then 
 \begin{align*}
  \bbE[X_1 + \dots + X_n \mid \mathcal{F}_m] &= \bbE[X_1 + \dots 
 + X_m \mid \mathcal{F}_m] + \bbE[X_{m+1} + \dots + X_n \mid \mathcal{F}_m]   \\
 &= X_1 + \dots + X_m + \bbE[X_{m+1} \mid \mathcal{F}_m] + \dots  + \bbE[X_n \mid \mathcal{F}_m]\\
 &= X_1 + \dots + X_m + \bbE[X_{m+1}] + \dots  + \bbE[X_n ]\\
 &= X_1 + \dots + X_m + (n-m)\mu
 \end{align*}
 
\end{exmp}

\begin{exmp}
    Let $X_1, \dots, X_n$ be i.i.d. with mean $0$ and variance $\sigma^2.$ Then 
    \begin{align*}
        \bbE[(X_1 + \dots + X_n)^2 \mid \mathcal{F}_m] &= S_m^2 + (n-m)\sigma^2.
    \end{align*}
\end{exmp}


\newpage
\subsection{Wednesday, Apr 30: Martingales}
\begin{defn}
    Let $\{X_t\}$ be a stochastic process. The \textbf{natural filtration} of $X_t$ is defined to be 
    \[\mathcal{F}_n = (X_1, \dots, X_n)\]
\end{defn}

\begin{defn}
    A stochastic process $\{M_n\}$ is called a martingale w.r.t. $\{\mathcal{F}_n\}$ if:
    \begin{enumerate}
        \item Each $M_n$ is $\mathcal{F}_n$ measurable.
        \item $\bbE[|M_n|] < \infty$ for all $n.$
        \item For each $m < n,$
        \[\bbE[M_n \mid \mathcal{F}_m] = M_m.\]
    \end{enumerate}
\end{defn}
\begin{rem}
    In particular, we can rewrite the Martingale Property to be $\bbE[M_n - M_m \mid \mathcal{F}_m] = 0.$ By the tower property, 

    \[\bbE[M_n] = \bbE[\bbE[M_n \mid \mathcal{F}_0]] = \bbE[M_0].\]
\end{rem}

\begin{prop}
    To prove $\bbE[M_n \mid F_m] = M_m$, it suffices to show that $\bbE[M_n \mid \mathcal{F}_{n-1}] = M_{n-1}$
\end{prop}
\begin{proof}
\[\bbE[M_n \mid \mathcal{F}_{n-2}] = \bbE[\bbE[M_n \mid \mathcal{F}_{n-1}]\mid \mathcal{F}_{n-2}] = \bbE[M_{n-1}\mid \mathcal{F}_{n-2}]= M_{n-2}\]
\end{proof}

\begin{exmp}
    Let $X_1, X_2, \dots$ be i.id. with mean $\mu,$ and let $\mathcal{F}_n$ be the natural filtration of $X_n.$ Let $S_0 = 0$ and $S_n = X_1 + \dots + X_n.$ Let $M_n = S_n - n\mu.$ 

    \begin{enumerate}
        \item The first property is inmediate.
        \item For any $n,$
        \[\bbE[|M_n|] \leq \bbE[|S_n|] + \mu n < \infty.\]
        \item For any $n,$
    \begin{align*}
        \bbE[M_n \mid \mathcal{F}_{n-1}] &= \bbE[(X_1 + \dots + X_n) - n\mu \mid \mathcal{F}_{n-1}]\\&= \bbE[M_{n-1} + (X_n - \mu) \mid \mathcal{F}_{n-1}]\\& = \bbE[M_{n-1} \mid \mathcal{F}_{n-1}] + \bbE[X_n - \mu \mid \mathcal{F}_{n-1}]\\& = M_{n-1}
    \end{align*}
    \end{enumerate}
\end{exmp}

\begin{exmp}
    Let $X_1, X_2, \dots$ be i.i.d. with mean $0$ and variance $\sigma^2.$ Let $\mathcal{F}_n$ be the natural filtration of $X_n.$ Let $M_n:= S_n^2 - n\sigma^2.$
    \begin{enumerate}
        \item Again, the first property is clear.
        \item For any $n,$
\[\bbE[|M_n|] \leq \bbE[S_n^2] + n\sigma^2 = \Var[S_n] - \bbE[S_n]^2 + n\sigma^2 = n\sigma^2 + n\sigma^2 < \infty\]
\item For any $n,$ we have (from Example 1.27)
\begin{align*}
    \bbE[M_n \mid \mathcal{F}_{n-1}] &= \bbE[S_n^2 - n\sigma^2 \mid \mathcal{F}_{n-1}]\\
    &= \bbE[S_n^2\mid \mathcal{F}_{n-1}] - n\sigma^2\\
    &= S_{n-1}^2 + \sigma^2 - \sigma^2 n\\
    &= M_{n-1}
\end{align*}
    \end{enumerate}
\end{exmp}

\begin{exmp}
    Let $Y_0, Y_1, \dots$ be a sequence of random variables and let $\mathcal{F}_n$ be the natural filtration. Let $X$ be a random variable such that $\bbE[|X|] < \infty,$ and let 
    \[M_n = \bbE[X \mid \mathcal{F}_n]\]
    \begin{enumerate}
        \item Clealry, $M_n$ is $\mathcal{F}_n$ measurable.
        \item For any $n,$
    \[\bbE[|M_n|] \leq \bbE[\bbE[|X| \mid \mathcal{F}_n]] = \bbE[|X|] < \infty.\]
    \item By the tower property,
\begin{align*}
    \bbE[M_n \mid \mathcal{F}_{n-1}] &= \bbE[\bbE[X \mid \mathcal{F}_{n}] \mid \mathcal{F}_{n-1}]\\
    &= \bbE[X \mid \mathcal{F}_{n-1}]\\
    &= M_{n-1}
\end{align*}
    \end{enumerate}
\end{exmp}


We know $\bbE[M_n] = \bbE[M_0]$ for any $n.$ Is this still true for a random time $\tau.$ 

\begin{rem}
    Let $\tau$ be a stopping time for $\{\mathcal{F}_n\}.$ Doob's Optional Stopping Theorem states that, under certain conditions, 
    \[\bbE[M_\tau] = \bbE[M_0]\]
\end{rem}
\begin{exmp}
(Gambler's ruin)
    Let $X_1, X_2, \dots$ be i.i.d with $\bbP\{X_i = 1\} = \bbP\{X_i = -1\} = \frac{1}{2}.$ Then $S_n = X_1 + \dots X_n$ is  a martingale by Example 1.28. Let $\tau := \min\{n \geq 0 \mid S_n = a \text{ or } S_n = -b\}.$
    DOST tells us that 
    \[\bbE[S_\tau] = \bbE[S_0] = 0,\] and thus 
    \begin{align*}
        0 &= \bbE[S_\tau]\\ &= a\bbP\{S_n = a\}  + (-b)\bbP\{S_n = -b\}\\
        &= a p_W - b p_L\\
        &= ap_W - b(1-p_W)
    \end{align*}
    and thus 
    \[p_W = \frac{b}{a + b}\]
\end{exmp}

\newpage
\subsection{Friday, May 2: Optional Stopping Theorem}
\begin{thm}
(OST I)
    Suppose $\{M_n\}$ is a Martingale with respect to some filtration $\{\mathcal{F}_n\},$ and let $\tau$ be a stopping time such that $\bbP\{\tau < K\} = 1$ for some constant $K.$ Then $\bbE[M_\tau] = \bbE[M_0].$
\end{thm}
\begin{proof}
    Note that $M_\tau = \sum_{n=0}^K M_n \mathbbm{1}_{\tau = n}.$ Then conditioning,
    \begin{align*}
        \bbE[M_\tau \mid \mathcal{F}_{K-1}] &= \bbE\left[\sum_{n=0}^K M_n \mathbbm{1}_{\tau = n} \mid \mathcal{F}_{K-1}\right]\\
        &= \sum_{n=0}^K \bbE\left[M_n \mathbbm{1}_{\tau = n}\mid \mathcal{F}_{K-1}\right]\\
        &= \sum_{n=0}^{K-1}\bbE\left[M_n \mathbbm{1}_{\tau = n}\mid \mathcal{F}_{K-1}\right] + \bbE\left[M_K \mathbbm{1}_{\tau = K}\mid \mathcal{F}_{K-1}\right]\\
        &= \sum_{n=0}^{K-1}M_n \mathbbm{1}_{\tau = n} + \bbE[\mathbbm{1}_{\tau = K}] \bbE[M_K \mid \mathcal{F}_{K-1}]\\
        &= \sum_{n=0}^{K-1}M_n \mathbbm{1}_{\tau = n} + \bbE[\mathbbm{1}_{\tau > K}] M_{K-1}\\
        &= \sum_{0}^{K-2}M_n \mathbbm{1}_{\tau = n} + M_{K-1}\mathbbm{1}_{K >K-2}
    \end{align*}
    Similarly, 
    \[\bbE[M_\tau \mid \mathcal{F}_{K-2}] = \sum_{0}^{K-3}M_n \mathbbm{1}_{\tau = n} + M_{K-3}\mathbbm{1}_{K >K-3}\] and so on until 
    \[\bbE[M_\tau \mid \mathcal{F}_0] = M_0\mathbbm{1}_{\tau \geq 1} = M_0.\] Using the tower property, 
    \[\bbE[M_\tau] = \bbE[\bbE[M_\tau \mid \mathcal{F}_0]] = \bbE[M_0]\]
\end{proof}

\begin{rem}
    Let $\{X_n\}$ be a simple random walk started at $0.$ We know $X_n$ is a martingale by Example 1.28. Let $\tau:= \min\{n \geq 1 \mid X_n = 1\}.$ Then $\bbP\{\tau < \infty\} = 1,$ but $\tau$ is not bounded. Note that $\bbE[X_\tau]= 1 \neq 0 = \bbE[X_0].$
    
    Recall that $\tau \wedge n = \min\{\tau ,n\}.$ Since $\tau\wedge n $ is a bounded stopping time, then by the optional stopping theorem, \[\bbE[M_0] = \bbE[M_{\tau \wedge n}] = \bbE[M_\tau \mathbbm{1}_{\tau \leq n}] + \bbE[M_n \mathbbm{1}_{\tau >n}].\] We would like to show that in the limit, the second term dies. 

    Since $\tau$ is finite, then $\mathbm{1}_{\tau >n} \to 0$ and $\mathbbm{1}_{\tau \leq n} \to 1$ and so $M_{\tau \wedge n}\to M_{\tau}.$ If $\bbE[|M_\tau|] < \infty$ and $\bbP\{\tau < \infty\} = 1,$ then we apply the Dominated convergence theorem with $X_n = M_\tau \mathbbm{1}_{\tau \leq n}$ and $Y = M_\tau.$ We know $Y$ dominates the $X_n$ and that $\mathbbm{1}_{\tau \leq n} \to 1$ and by the DCT, 
    \[\bbE[M_\tau\mathbbm{1}_{\tau \leq n}] \to \bbE[M_\tau].\] Similarly, $\bbE[M_n \mathbbm{1}_{\tau > n}] \to 0$
\end{rem}
This remark leads to the following result:
\begin{thm}
    (OST II) Let $\tau$ be a stopping time and assume that 
    \begin{enumerate}
        \item $\bbP\{\tau < \infty\} = 1.$
        \item $\bbE[|M_\tau|] < \infty$
        \item $\bbE[M_n\mathbbm{1}_{\tau > n}] \to 0.$
    \end{enumerate}
    Then $\bbE[M_\tau] = \bbE[M_0].$
\end{thm}

\begin{rem}
    If $M_n$ is bounded, i.e, there exists a $c$ such that $|M_n| < c$ for all $n,$ then by Jensen's inequality
    \begin{align*}
        \bbE[M_n\mathbbm{1}_{\tau > n}] \leq c\bbP\{\tau >n\} \to 0
    \end{align*}
\end{rem}

\begin{exmp}
    We are going to formally provide the solution to the Gambler's ruin model in example 1.31. Let $X_n$ be the martingale modeling the random walk started at $0$, and $\tau := \min\{n \geq 0 \mid X_n = a \text{ or } S_n = b\}.$ Since the random walk is recurrent, we have that $\bbP\{\tau < \infty\} = 1.$ Also, we have that $\bbE[|X_\tau|] < \infty$ since $X_\tau$ is either $a$ or $b$. Then 
    \begin{align*}
        \bbE[|X_n|\mathbbm{1}_{\tau >n}] \leq \max\{a,b\}\bbP\{\tau >n\} \to 0.
    \end{align*}
    Now and only now can we proceed as in Example 1.31.
\end{exmp}



\newpage
\subsection{Monday, May 5: Applications of the OST}
\begin{exmp}
    Let $\{X_n\}$ be a symmetric random walk on $\bbZ,$ and let $\tau := \min\{n >0 : X_n = a \text{ or }X_n = b \mid X_0 = 0\}.$ Then let $M_n := X_n^2 - n.$ Recall from Example 1.29 that $M_n$ is a martingale (noting that $\sigma^2 = 1$) with respect to $\mathcal{F}_n.$ 

    We claim that $\bbP\{\tau > n\} \leq e^{-cn}$ for some $c>0.$ To see this, note that the random walk stopped when we hit $a$ or $-b$ is a Markov chain on $S = \{-b, -b + 1, \dots, a-1, a\}$ with absorbing ends. Then $\{-b + 1, \dots, a-1\}$ is a transient communication class. It is a simple consequence of Proposition 5 that the probability that we stay in $\{-b +1, \dots, a-1\}$ is bounded above by $e^{-cn}$ for some $c>0.$ Using this bound, we have that 
    \[\bbE[\tau] = \sum_{n=0}^\infty \bbP\{\tau \geq n\}\leq \sum_{n=0}^\infty e^{-cn} < \infty\] and thus
    \[\bbE[|X_\tau|] \leq \bbE[X_\tau^2] + \bbE[\tau] \leq \max\{a^2, b^2\} + \bbE[\tau] < \infty\]
    Moreover, 
    \[\bbE[|M_n|\mathbbm{1}_{\tau >n}] \leq (\max\{a,b\}^2 + n)e^{-cn} \to 0. \] We can now apply the optional stopping theorem (ii), we have that 
    \[ 0= \bbE[M_0] = \bbE[M_\tau] = \bbE[X_\tau^2] - \bbE[\tau] = \bbP\{X_\tau = a\}a^2+ \bbP\{X_\tau = -b\}b^2 - \bbE[\tau].\] From Example 1.31,
    \[0 = \frac{a^2 b  + b^2 a}{a + b} - \bbE[T] = ab - \bbE[T] \implies \bbE[T] = ab.\]
\end{exmp}


\begin{exmp}
    At each toss of a coin, you win $\$1$ if $T$ and lose a buck if $H$. Let $X_n$ be the winnings on round $n.$ Then 
    \[\bbP\{X_n = 1\} = \bbP\{X_n= -1\} = \frac{1}{2}.\] Then if $Y_n = \sum_{i=1}^n X_i,$ we have shown in Example 1.28 that $Y_n$ is a martingale. By OST, we know that if $\tau:= \min\{n >0 \mid X_n = T\},$ then
    \[0 = \bbE[Y_0] = \bbE[Y_\tau] = \bbE[\sum_{n=0}^\tau X_n] = \bbE[(-1)(\tau-1) + 1] \implies \bbE[\tau] = 2.\]

    Note that if the coin were biased with $\bbP\{H\} = p,$ then for every $\$1$ bet you make, you are compensate $\$(1 - 2p).$
\end{exmp}

\begin{exmp}
    I am a monkey at a typewriter with only capital letters. How long will it take for me, the monkey, to type out 
    \begin{center}
        ABRACADABRA
    \end{center}
    Some rich assholes bet on my typing such that just before time $n,$ a new gambler arrives and bets $\$1$ that the $n$th letter will be A. If he loses, he dies. If he wins, he wins $\$26$ and bets all of it that the $n+1$th letter will be B. Repeat with the rest of the letters in ABRACADABRA. Denote the winnings of the $j$th better out of $n$ after $n$ rounds by $M_n^j.$ This is a martingale since 
    \[\bbE[M_n^j \mid \mathcal{F}_{n-1}] = \begin{cases}
        0, \quad \text{if he loses sometime before $n$}\\
        26^n \frac{1}{26} + 0 \frac{25}{26} = 26^{n-1}
    \end{cases} = M_{n-1}^j.\] Let $M_n = \sum_{j=1}^n M_n^j$ be total winnings on all the betters before round $n+1.$ We will see on a PSET that $M_n$ is a martingale and that we can apply the OST. Thus, if $\tau = \min\{n >0 \mid \text{ we see ABRACADABRA}\},$ then 
    \[\bbE[M_0] = 0 = \bbE[M_\tau] = \bbE[\sum_{j=1}^\tau M_n^j]= \bbE[(26^{11} - 1) + (26^4) + (26 -1) + (-1)(\tau - 3).]\] Thus, 
    \[\bbE[\tau] = 26^{11} + 26^4 + 26\]
\end{exmp}



\newpage
\subsection{Wednesday, May 7: Martingale Convergence Theorem}
\begin{exmp}
    Let $\mathcal{F}_n$ be a filtration, and $X$ be a r.v. with $\bbE[|X|]< \infty.$ Define 
    \[M_n:= \bbE[X \mid \mathcal{F}_n].\] We've shown that $M_n$ is a martingale. The MCT will tell us that $M_n$ converges as $n\to \infty$
\end{exmp}

\begin{prop}
    Let $M_n$ be a martingale with respect to $\mathcal{F}_n,$ let $\tau$ be a stopping time. Then $M_{n\wedge \tau}$ is a Martingale.
\end{prop}

\begin{proof}
    \begin{itemize}
        \item To show $M_{n\wedge \tau}$ is $\mathcal{F}_{n}$ measurable, noe that 
        \[M_{n\wedge \tau} = M_n\mathbbm{1}_{n < \tau} + \sum_{k=0}^n M_k \mathbbm{1}_{\tau = k}\] is clearly $\mathcal{F}_{n}$ measurable.
        \item We have 
        \[|M_{n\wedge t}| \leq |M_n| + \sum_{k=0}^n |M_k|,\] and the result follows from taking expectation.
        \item 
        \begin{align*}
            \bbE[M_{n \wedge \tau} \mid \mathcal{F}_{n-1}] &= \bbE[M_{n\wedge \tau}\mathbbm{1}_{\tau >n} \mid \mathcal{F}_{n-1}] + \bbE[M_{n} \wedge \tau \mathbbm{1}_{\tau \leq n} \mid \mathcal{F}_{n-1}]\\
            &= \bbE[M_n \mathbbm{1}_{\tau >n} \mid \mathcal{F}_{n-1}] + \bbE[M_\tau \mathbbm{1}_{\tau \leq n} \mid \mathcal{F}_{n-1}]\\
            &= \bbE[M_n \mid \mathcal{F}_{n-1}] \mathbbm{1}_{\tau >n} + M_\tau \mathbbm{1}_{\tau \leq n}\\
            &= M_{n-1} \mathbbm{1}_{\tau >n} +M_\tau \mathbbm{1}_{\tau \leq n}\\
            &= M__{n-1\wedge \tau}
        \end{align*}
    \end{itemize}
\end{proof}
\begin{thm}
(Martingale Convergence Theorem) Let $M_n$ be a martingale and suppose there exists some $C>0$ such that $\bbE[|M_n|] \leq C$ for all $n>0.$ Then with probability $1,$ there exists a random variable $M_\infty$ such that 
\[\lim_{n\to \infty} M_n = M_\infty\]
\end{thm}
\begin{proof}
    Suppose $M_n$ doesn't converge. By necessity, it must be true that 
    \[\liminf_{n\to \infty}M_n < \liminf_{n\to \infty}M_n.\] Take $a,b \in \bbR$ such that there exist times $m_1 < n_1 < m_2 < n_2 < \dots< $ so that 
    \[M_{m_j} \leq a, \quad M_{n_j} \geq b \qquad \forall j \in \bbN.\] We say that an \textbf{upcrossing} of $[a,b]$ is an interval $\{m, \dots, n\}$ such that $M_{m} \leq a$ and $M_n \geq b$ and $M_k \in (a,b)$ for all $k$ in the uncrossing. Note that since $M_n$ doesn't converge, we must have that $M_n$ has an infinite number of upcrossings for some interval $[a,b].$
    
    Define $B_0:=1,$ and
    \[B_n:= \begin{cases}
        1 \qquad B_{n-1} = 0, \quad M_{n-1}\leq a\\
        0, \qquad B_{n-1} = 1, \quad M_{n-1} \geq b\\
        B_{n-1}
    \end{cases}\] to be the betting strategy where you buy, to the best of your ability, a `stock' when $M_n$ is less than $a$ and sell a `stock' when  $M_n$ is greater than $b.$ Then we can define $W_n$ to be our total winnings at time $n$ by 
    \[W_n = \sum_{k=0}^n B_k (M_k - M_{k-1}).\] $W_n$ is a \textbf{discrete stochastic integral} and is clearly $\mathcal{F}_n-$measurable with $\bbE[|W_n|] < \infty.$ Moreover, we can say that because $B_n$ is $\mathcal{F}_{n-1}-$measurable, 
    \begin{align*}
        \bbE[W_n \mid \mathcal{F}_{n-1}] &= \bbE\left[\sum_{k=0}^n B_k(M_{k} - M_{k-1})\mid \mathcal{F}_{n-1}\right]\\
        &= \sum_{k=0}^{n-1} B_k(M_{k} - M_{k-1}) + \bbE[B_n (M_n - M_{n-1})\mid \mathcal{F}_{n-1}]\\
        &= W_{n-1} + B_n\bbE[ (M_n - M_{n-1})\mid \mathcal{F}_{n-1}]\\
        &= W_{n-1} + B_n\bbE[M_n\mid \mathcal{F}_{n-1}] - B_n M_{n-1}\\
        &= W_{n-1}
    \end{align*}
    Thus, $W_n$ is a martingale. Let $U_n$ be the number of upcrossings by time $n.$ Each $U_n$ results in a profit of at least $(b-a),$ and so 
    \[W_n \geq (b-a) U_n + (M_n - a),\] where the last term represents the loss of holding on to the asset at the present. Thus, 
    \[0 =\bbE[W_0]= \bbE[W_n] \geq (b-a)\bbE[U_n] + \bbE[M_n]- a.\] Rearranging,
    \[\bbE[U_n] \leq \frac{a - \bbE[M_n]}{b-a} \leq \frac{|a| + \bbE[|M_n|]}{b-a} < \frac{|a|  + C}{b-a}.\] Because this holds for al $n,$ then 
    \[\lim_{n\to \infty}\bbE[U_n] < K\] for some $K.$ Since for any $n,$ $U_n \geq 0$ and $U_{n-1} \leq U_n,$ then 
    \[\lim_{n\to \infty}\bbE[U_n] = \bbE[\lim_{n \to \infty} U_n] < K.\] But this in turn implies that $\lim_{n\to \infty}U_n < \infty,$ which is a contradiction. 
\end{proof}

\begin{rem}
Consider the following assumptions:
    If $M_n \geq -k$ for all $n,$ then 
    \begin{align*}
        \bbE[|M_n|] &= \bbE[M_n \mathbbm{1}_{M_n \geq 0}] +\bbE[M_n \mathbbm{1}_{M_n < 0}] \\
        &\leq \bbE[M_n \mathbbm{1}_{M_n \geq 0}] + k\\
        &\leq \bbE[M_n + k] + k\\
        &\leq \bbE[M_0] + 2k
    \end{align*}
    If $M_n \in L_2,$ then 
    \[\bbE[|M_n|] = \bbE[M_n \cdot 1] \leq \left(\bbE[|M_n|^2]\right)^\frac{1}{2}\left(\bbE[1]\right)^\frac{1}{2} \leq C^\frac{1}{2}\]

    The limit $M_\infty$ is a random variable: Let $X_n$ be a random walk on $\bbZ,$ and let $\tau := \inf \{x \mid X_n \in \{a, b\}\}.$ Then by Proposition 29, $X_{n\wedge \tau}$ is a martingale that is uniformly bounded. Clearly, \[\lim_{n\to \infty} X_{n\wedge \tau} = X_\tau =\begin{cases}
        -a, \quad \text{w.p.} \frac{1}{2}\\
        b, \quad \text{w.p.} \frac{1}{2}
    \end{cases}.\] 
    
    While we might expect that $\bbE[M_\infty] = M_0$ by the optional stopping theorem, this is usually not the case. To see this, let $X_n$ be a random walk on $\bbZ$ and $\tau = \inf\{n : X_n= 1 \mid X_0 = 0\}.$ Then 
    \[\bbE[\lim_{n\to \infty} X_{n\wedge \tau}] = \bbE[X_\tau] = 1 \neq \bbE[X_0] = 0.\]

    Why do we need the assumption of boundedness? Let $X_n$ be a random walk on $\bbZ.$ We know that $X_n$ is a martingale, but clearly $\bbE[|X_n|]$ is unbounded. In particular, 
    $\displaystyle\lim_{n\to \infty} X_n$ does not exist.
\end{rem}

\begin{exmp}
    Recall that $\sum \frac{1}{n} = \infty$ and $\sum \frac{(-1)^n}{n}$ converges. Suppose $Y_n$ is a random variable such that $Y_n \in \{-1, 1\}$ w.p. $\frac{1}{2}.$ What is $\sum \frac{Y_n}{n}.$ It is not hard to see that 
    \[M_n = \sum_{k=0}^n \frac{Y_k}{k}\] is a martingale. To apply MCT, we saw in Remark 21 that it suffices to show that $M_n \in L_2.$ Note that 
    \[\bbE[|M_n|^2] = \sum_{k=0}^n \sum_{j=0}^n \bbE[Y_k Y_j] \frac{1}{kj} = \sum_{k=0}^n \bbE[Y_k^2]\frac{1}{k^2} < \infty.\] Thus, we apply MCT to note that $M_n \to M_\infty = \displaystyle\sum_{k=0}^\infty \frac{Y_k}{k}$ and so the series converges.
\end{exmp}

\begin{exmp}
    (Polya's Urn) We have an urn with red and green balls, starting with a single red and a single green ball. A time $n,$ we pick a ball, put it back, and add another of the same color. Let $X_n = \#\{\text{red balls}\}.$ Note that are $N + 2$ balls at time $N.$ Thus,
    \[\bbP\{X_{n + 1} = x+1 \mid X_n = x\} = \frac{x}{n+2}, \quad \bbP\{X_{n+ 1} = x \mid X_n = x\} = \frac{n + 2 - x}{n+2}\] Define 
    \[M_n = \frac{X_n}{n+2}\] to be the proportion of red bals in the urn. We claim that this is a martingale since 
    \[\bbE[M_{n+1]} \mid \mathcal{F}_n] = \frac{X_n}{n+2}\frac{X_n + 1}{n+3} + \frac{n+2 - x}{n+2}\frac{X_n}{n+3} = \frac{X_n}{n+2} = M_n.\] Since this martingale is bounded by $1,$ then 
    \[\lim_{n\to \infty} M_n = M_\infty \sim U([0,1]).\]
\end{exmp}

\newpage
\subsection{Monday, May 12: Introduction to Brownian Motion}
Informally, a Brownian motion $\{B_t\}_{t\geq 0}$ is a random function indexed by continuous time taking values in continuous space. 
\begin{defn}
    A \textbf{Brownian motion} is a a random function $B: [0,\infty) \to \bbR$ that satisfies:
    \begin{enumerate}
        \item $B_0 = 0;$
        \item (Stationary increments) For every $0< s< t,$ $B_t - B_s$ has the same distribution as $B_{t-s};$
        \item (Independent increments) For every $s_1 \leq t_1 \dots s_k \leq t_k,$ the increments $B_{t_j} - B_{s_j}$ are independent for $j = 1,2,\dots, k;$
        \item (Continuity) $t\mapsto B_t$ is continuous. 
    \end{enumerate}
\end{defn}
\begin{thm}
    Let $B: [0, \infty) \to \bbR$ be a random continuous function with independent, stationary increments and $B_0 = 0.$ Then there exists some $\mu \in \bbR$ and $\sigma^2 >0$ such that $B_t \sim N(\mu t, \sigma^2 t),$ where $\mu$ and $\sigma^2$ uniquely characterize the distribution of $\{B_t\}_{t\geq 0}$
\end{thm}
\begin{rem}
There are two way of building $B_t:$

   (i) Suppose $X_n$ is our coin flip random variable and $S_n = \sum X_i.$ Then by the CLT, if $\Phi$ is the CDF of the standard normal,
    \[\lim_{n\to \infty}\bbP\{a < \frac{S_n}{\sqrt{n}} < b\} = \Phi(b) - \Phi(a).\]

    Now let 
    \[B_n^{(t)} := \frac{S_{\lfloor nt\rfloor}}{\sqrt{nt}}.\] A theorem by Donsker states that $B_n^{(t)}\xrightarrow[n\to \infty]{}B_t.$

    (ii) Levy's Construction is done by linearly interpolating a family of Normal r.v.'s indexed by a countably dense subset of $[0,1].$
\end{rem}
\begin{defn}
    \textbf{(Standard) Brownian motion} is the process $\{B_t\}_{t\geq 0}$ with $B_0 = 0$ satisfying:
    \begin{enumerate}
        \item $B$ is continuous
        \item For each $s<t,$ $B_t - B_s$ has the normal distribution with mean $0$ and variance $t - s.$
        \item For every $s_1 \leq t_1 \leq \dots s_k \leq t_k,$ the increments $B_{t_j} - B_{s_j}$ are independent.
    \end{enumerate}
\end{defn}
\begin{exmp}
    Suppose $B$ is a standard Brownian Motion. Then 
    \[\bbP\{B_1 \geq 1, B_3 \geq B_1 + 1\} = \bbP\{B_1 \geq 1, B_3 - B_1 \geq 1\}\] By (c) and then (b), 
    \[\bbP\{B_1 \geq 1, B_3 - B_1 \geq 1\} = \bbP\{B_1 \geq 1\} \bbP\{B_3 - B_1 \geq 1\} = \int_1^\infty \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\, dx\int_1^\infty \frac{1}{2\sqrt{\pi }}e^{-\frac{x^2}{4}}\,dx\]
\end{exmp}
\begin{prop}
    Let $B_t$ be a standard Brownian motion and let $c >0.$ Then $\frac{1}{\sqrt{c}}B_{ct}$ is a standard Brownian motion. 
    \end{prop}
    \begin{proof}
    Clearly, the new motion is continuous and has independent increments. For any $s\leq t,$ we have that 
    \[B_{ct} - B_{cs} \sim N(0, c(t-s)) \implies \frac{1}{\sqrt{c}}(B_{ct} - B_{cs})\sim N(0,t-s)\]
\end{proof}
\begin{prop}
    For each fixed $t\geq 0,$ it holds w.p. $1$ that $B$ is not differentiable at $t.$
\end{prop}
\begin{proof}
    Let $\epsilon>0,$ we have by the previous proposition that $\frac{1}{\sqrt{\epsilon}}(B_{t + \epsilon } - B_t)\sim N(0,1),$ and so 
    \[\frac{B_{t + \epsilon} - B_t}{\epsilon} \sim \frac{1}{\sqrt{\epsilon}} Z,\] where $Z\sim N(0,1).$ Thus, 
    \[\bbP\{\frac{|B_{t + \epsilon} - B_t|}{\epsilon} \geq c\} = \bbP\{|Z| \geq \epsilon^\frac{1}{2}c\} \to 1,\] and so 
    \[\limsup_{n\to \infty}\frac{B_{t + \epsilon} - B_t}{\epsilon} = \infty.\]
\end{proof}

\newpage
\subsection{Wednesday, May 14: Applications of Brownian Motion}
\begin{rem}
    Suppose $\{X_n\}$ is a discrete stochastic process, and $A\subset S$ has $\bbP\{X_n \in A\}= 0$ for any $n.$ Then 
    \[\bbP\{\exists \, n : X_n \in A\} \leq \sum_{n=0}^\infty \bbP\{X_n \in A\} = 0.\] This is not true for B.M. We know that $\bbP\{B_t = 0\},$ but we will see in this class that 
    \[\bbP\{\exists \, t : B_t = 1\}\]
\end{rem}


\begin{exmp}
    Suppose $B$ is S.B.M. Then 
    \begin{enumerate}
        \item 
        \[\bbE[B_4 \mid B_2 = 6] = \bbE[B_4 - B_2 + B_2 \mid B_2 = 6] = \bbE[B_4- B_2] + \bbE[B_2 \mid B_2] = 6\]
        \item  Suppose $s\leq t,$ then
        \begin{align*}
           \bbE[B_s^2 B_t^2] &= \bbE[B_s^2(B_t - B_s + B_s)^2]\\
           &= \bbE[\left(B_s(B_t - B_s)+ B_s^2\right)^2]\\
           &= \bbE[B_s^2(B_t - B_s)^2 + 2B_s^3(B_t - B_s) + B_s^4]\\
           &= \bbE[B_s]^2\bbE[B_t - B_s]^2 + 2\bbE[B_s^3]\bbE[B_t - B_s]+ \bbE[B_s^4]\\
           &= s(t-s) + 0 + 3s^2\\
           &= s(t-s) + 3s^2
        \end{align*}
        Where the fourth moment can be calculated using the moment-generating function of $X\sim N(0,1).$ 
        \[\bbE[X^{2n}]= (2n-1)!! \sigma^{2n}\]
        \item Find 
        \[\bbP\{B_2 >B_1 > B_3\}.\] Let $X = B_1,$ $Y = B_2 - B_1$ and $Z = B_3 -B_2.$ It suffices to find
        \begin{align*}
            \bbP\{X + Y > X > X + Y  + Z\} &= \bbP\{Y >0 > Y + Z\}\\
            &= \bbP\{B_1 >0, B_2 < 0\}\\
            &= \int_0^\infty\bbP\{B_2 < 0 \mid B_1  = x\}\frac{1}{\sqrt{2\pi }}e^{-\frac{x^2}{2}}\,dx\\
            &= \int_0^\infty\bbP\{B_2 < -x \mid B_1  = 0\}\frac{1}{\sqrt{2\pi }}e^{-\frac{x^2}{2}}\,dx\\
            &= \int_0^\infty\bbP\{B_2 > x \mid B_1  = 0\}\frac{1}{\sqrt{2\pi }}e^{-\frac{x^2}{2}}\,dx\\
            &= \int_0^\infty\left(\int_x^\infty  \frac{1}{\sqrt{2\pi}}e^{-\frac{y^2}{2}}\right)\frac{1}{\sqrt{2\pi }}e^{-\frac{x^2}{2}}\,dx\\
            &= \frac{1}{2\pi}\int_0^\infty \int_0^\infty e^{-(\frac{y^2 + x^2}{2})}\,dxdy\\
            &= \frac{1}{2\pi}\int_\frac{\pi}{4}^{\frac{\pi}{2}}\int_0^\infty e^{\frac{r^2}{2}}r\,dr\theta\\
            &= \frac{1}{8}
        \end{align*}
    \end{enumerate}
\end{exmp}



\newpage
\subsection{Friday, May 16: Properties of Brownian Motion}
\begin{defn}
    A continuous-time stochastic process $M_t$ is a \textbf{martingale} with respect to $\mathcal{F}_t$ if:
    \begin{enumerate}
        \item $M_t$ is $\mathcal{F}-$measurable.
        \item $\bbE[|M_t|] < \infty$ for all $t.$
        \item For all $u >t,$ 
        \[\bbE[M_u \mid \mathcal{F}_t] = M_t.\]
    \end{enumerate}
\end{defn}
\begin{prop}
    (Markov Property) Let $\{B_t\}$ be a SBM. Then for each $t\geq 0,$ the process $\{B_{s + t} - B_t\}_{s\geq 0}$ is an SBM independent of $\mathcal{F}_t.$ 

    (Martingale Property) $B$ is a martingale w.r.t. $\mathcal{F}_t$
\end{prop}
\begin{proof}
    We show the martingale property. Take $u>t.$ Then 
    \begin{align*}
        \bbE[B_u \mid \mathcal{F}_t] &= \bbE[B_{u-t} \mid \mathcal{F}_t] + \bbE[B_t \mid \mathcal{F}_t]\\
        &= \bbE[B_{u-t}] + B_t\\
        &= B_t
    \end{align*}
\end{proof}

\begin{defn}
    A random variable $\tau \in [0, \infty]$ is a \textbf{stopping time} for $\mathcal{F}_t$ if, for any $t\geq 0,$ we have that $\{\tau \leq t\}$ is $\mathcal{F}_t-$measurable. 
\end{defn}
\begin{exmp}
    For $a\in \bbR,$ let $\tau = \min\{t \geq 0 \mid B_t = a\}$ is a stopping time. $\tau' = \max\{t\leq 1 \mid B_t= a\}$ is \textit{not} a stopping time.
\end{exmp}

\begin{thm}
    (OST) Let $\{M_t\}_{t\geq 0}$ be a martingale w.r.t $\{\mathcal{F}_t\}$ such that $t\mapsto M_t$ is continuous. Let $\tau$ be a stopping time and suppose there is a $c>0$ such that 
    \[\bbP\{\tau < \infty, |M_t| \leq C, \forall\,t\leq \tau\} = 1.\] Then 
    \[\bbE[M_\tau] = \bbE[M_0].\]
\end{thm}

\begin{prop}
    Suppose $B$ is an SBM and define 
    \[\tau:= \min\{t \geq 0 \mid B_t =a \text{ or } B_t = -b\}.\] Then 
    \[\bbP\{B_\tau = a\} = \frac{b}{a + b}\]
\end{prop}
\begin{proof}
    We know that since $B_t$ has not struck $a$ or $b$ when $\tau >t,$ we have that 
    \[\bbP\{\tau >t \}\leq \bbP\{B_t \in [-b, a]\} \to 0\implies \bbP\{\tau < \infty\} = 1.\]
    We also know that for $t\leq \tau,$
    \[|B_t| \leq \max\{|a|, |b|\}.\] Hence, by the OST
    \[\bbE[B_\tau]=\bbE[B_0] = 0\] but 
    \[\bbE[B_\tau]= \bbP\{\tau = a\}a + \bbP\{\tau = -b\}(-b)= \bbP\{\tau = a\}a + (1-\bbP\{\tau = a\})(-b) = 0\]
\end{proof}

\begin{prop}
    Brownian motion is recurrent in one dimension. That is, for each $T\geq 0 ,$ 
    \[\bbP\{\exists t>T: B_t = 0\} = 1\]
\end{prop}
\begin{proof}
    The process 
    $\{B_{T + t} - B_T\}_{t\geq 0}$ is an SBM independent of $\mathcal{F}_T$ by the Markov property. It suffices to show that there exists some $t$ such that $B_{T + t} - B_T = -B_T$ almost surely. We use the previous result with $b = -B_T$ and $a>0$ to find that 
    \[\bbP\{B_{T + t} - B_T = a \text{ before } -B_T\}  =\frac{B_T}{a + B_T} \xrightarrow[a\to \infty]{} 0 .\] 
\end{proof}


\newpage
\subsection{Monday, May 19: The Reflection Principle}

\begin{prop}
    (Strong Markov Property) Let $\tau$ be a stopping time for $B_t.$ The process $\{B_{ s + \tau} - B_\tau\}_{s\geq 0}$ is a Brownian motion and is independent of $\mathcal{F}_\tau.$
\end{prop}


\begin{prop}
    Let $B_t$ be a SBM and let $a >0.$ Then 
    \[\bbP\{\max_{0 \leq s \leq t}B_s \geq a\} = 2\bbP\{B_t \geq a\}\]
\end{prop}
\begin{proof}
    Define 
    \[\tau:= \min\{t\geq 0 : B_t = a\}.\] Then $\tau$ is a stopping time w.r.t. $\mathcal{F}_t.$ Thus, 
    \[\{\max_{0\leq s\leq t}B_s \geq a\} = \{\tau \leq t\}\] and so using the law of total probability and then the strong markov property on the event $\tau \leq t,$ we know that 
    \[B_t - B_\tau = B_t - a \sim N(0, t - \tau)\]
    \begin{align*}
        \bbP\{B_t \geq a\} &= \bbP\{B_t \geq a \mid \tau \leq t\}\bbP\{\tau \leq t\} + \bbP\{B_t \geq a \mid \tau \geq t\}\bbP\{\tau >t\}\\
        &= \bbP\{B_t \geq a \mid \tau \leq t\}\bbP\{\tau \leq t\} + 0\\
        &= \bbP\{B_t - a \geq 0 \mid \tau \leq t\}\bbP\{\tau \leq t\}\\
        &= \frac{1}{2} \bbP\{\tau \leq t\}
    \end{align*}
\end{proof}

\begin{exmp}
    Let $\{B_t\}$ be a SBM. For $t>1,$ we wish to compute $\bbP\{B_s = 0 \text{ for some } 1\leq s \leq t\}.$ Suppose $B_1 = a >0.$ Then the probability $B_s = 0$ for some $s \in [1,t]$ is the same as probability that $B_s \leq a$ for some $0\leq s \leq t-1.$ By symmetry, this is the same as the probability that $B_s \geq a$ for some $0\leq s \leq t-1.$ Thus, 
    \begin{align*}
    \bbP\{B_s = 0 \text{ for some } 1 \leq s \leq t \mid B_1 = a\}&= \bbP\{B_s \geq a \text{ for some $0\leq s \leq t-1$}\}\\ &= 2\bbP\{B_{t-1} \geq a\}\\
    &= 2\int_a^\infty \frac{1}{\sqrt{2\pi (t-1)}}e^{-\frac{x^2}{2(t-1)}}
    \end{align*}
    Averaging over all possible values of $a,$ 
    \[\bbP\{B_s = 0\text{ for some } 1\leq s \leq t\} = 2\int_{-\infty}^\infty \left(\int_a^\infty \int_a^\infty \frac{1}{\sqrt{2\pi (t-1)}}e^{-\frac{x^2}{2(t-1)}}\right) \frac{1}{\sqrt{2\pi} }e^{-\frac{a^2}{2}}\,da = 1 - \frac{2}{\pi}\arctan \frac{1}{\sqrt{t-1}}\]
    
\end{exmp}



\newpage
\subsection{Wednesday, May 21: Multi-Dimensional Brownian Motion}
\begin{defn}
Let $d \in \bbN.$ The \textbf{Gaussian (normal) distribution in $\bbR^d$ } with mean $0$ and covariance matrix $\sigma^2 I$ is the distribution of 
\[\overline{X} = (X_1, \dots, X_d),\] where each $X_i \sim N(0,\sigma^2)$ i.i.d. 
\end{defn}

\begin{rem}
The density of $\overline{X}$ is given by 
\[\prod_{j=1}^d \frac{1}{\sqrt{2\pi \sigma^2}}e^{\frac{-x_j^2}{2\sigma^2}} = \frac{1}{(2\pi \sigma^2)^{\frac d2}}\exp\{\frac{-|\overline{x}|^2}{2\sigma^2}\}\]
\end{rem}

\begin{prop}
Let $\overline{X}$ be a normal r.v. in $\bbR^d$ with mean $0$ and covariance matrix $\sigma^2 I $ and let $Q$ be an $n\times n$ orthonormal matrix. Then $Q\overline{X} \substack{d\\=} \overline{X}$
\end{prop}

\begin{defn}
The \textbf{standard Brownian motion in $\bbR^d$} is the stochastic process $\{\overline{B}_t\}_{t\geq 0} = \{(B_t^1, B_t^2, \dots, B_t^d)\}_{t\geq 0}$ where $B_t^1, \dots, B_t^d$ are independent one dimensional standard Brownian motions. 
\end{defn}

\begin{prop}
The S.B.M. in $\bbR^d$ is the unique stochastic process taking values in $\bbR^d$ satisfying:
\begin{enumerate}
\item $\overline{B}_0 = 0$;
\item $\overline{B}$ is continuous;
\item For each $s< t,$ $(\overline{B}_t - \overline{B}_s)$ has a multivariate Gaussian distribution with mean $0$ and covariance matrix $(t-s)I.$ 
\item For $s_1 \leq t_1 \leq \cdots s_k \leq t_k \leq \cdots $ the increments $\overline{B}_{t_j}- \overline{B}_{s_j}$ are independent.
\end{enumerate}
\end{prop}

\begin{rem}
Multi-dimensional B.M. satisfies some things that the one-dimensional B.M did:
\begin{itemize}
\item $\overline{B}$ satisfies Brownian scaling. I.e, $\{\sqrt c \overline{B}_{ct}\} =^d \{\overline{B}\}$
\item $\overline{B}$ satisfies the Markov property and the strong Markov property.
\end{itemize}
\end{rem}

\begin{exmp}
Suppose $\{W_t\}$ is a 2D B.M starting at $(1,1).$ What is the probability that $W_t$ hits the positive real axis before it hits the negative real axis. We can write 
\[W_t = \begin{pmatrix} 1\\1\end{pmatrix} + \begin{pmatrix}B_t^1 \\B_t^2\end{pmatrix}\] where $B_t^1, B_t^2$ are S.B.M. Let
\[\tau = \inf\{t \geq 0 : (1,1) + (B_t^1, B_t^2) \in \bbR \times (-\infty, 0]\} = \inf\{\tau \geq 0 : 1+ B_t^2 \leq 0\}\]
Then $\tau$ is a stopping time w.r.t. $\mathcal{F}_t^2.$ We seek 
\[\bbP\{1 + B_\tau^1 \geq 0\} = 1-\bbP\{B_\tau^1 \leq -1\}.\] Conditioning, 
\begin{align*}
\bbP\{B_\tau^1 \leq -1\} &= \int_0^\infty \bbP\{B^1_t \leq -1 \mid \tau = t\}\bbP\{\tau = t\}\,dt\\
&= \int_0^\infty \bbP\{B_t^1 \leq -1 \mid \tau = t\}f_\tau(t)\,dt\\
&= \int_0^\infty \bbP\{B_t^1 \leq -1\}f_\tau(t)\,dt
\end{align*}
We know by the Reflection Principle that
\[\bbP\{\tau \leq t\} = 2\bbP\{B_t^1 \leq -1\}\] and thus
\begin{align*}
\int_0^\infty \bbP\{B_t^1 \leq -1\}f_\tau(t)\,dt &= 2\int_0^\infty \bbP\{B_t^1 \leq -1\}d\bbP\{B_t^{1} \leq -1\}\,dt\\
&= (\bbP\{B^1_t \leq -1\}^2)_0^\infty\\
&= \lim_{t\to \infty}\left(\bbP\{B^1_t \leq -1\}\right)^2\\
&= \lim_{t\to \infty} \left(B_1^1 \leq \frac{-1}{\sqrt{t}}\right)^2\\
&= \lim_{t\to \infty} (\Phi(\frac{-1}{\sqrt{t}}))^2\\
&= \frac{1}{4}
\end{align*}
and so our answer is $\frac{3}{4}.$
\end{exmp}

\newpage

\subsection{Friday, May 23: The Heat Equation}
\begin{defn}
    Let $f\in C^2(\bbR^d, \bbR).$ The \textbf{Laplacian} of $f$ is defined by 
    \[\Delta f (\overline{x}) = \sum_{i=1}^d \frac{\partial^2 f(x_i)}{dx_i^2}.\]
\end{defn}
\begin{thm}
    Let $f\in C^2(\bbR^d \times [0,\infty), \bbR)$ and assume that for each $t>0,$ there is some $C_t$ such that 
    \[|f(\overline{x}, t)| \leq C_t e^{C_t |\overline{x}|}\] and so are its partials. Assume $f$ also satisfies the \textbf{heat equation}, i.e, 
    \begin{align}
    \frac{\partial}{\partial t}f(\overline{x}, t) + \frac{1}{2}\Delta_{\overline{x}} f(\overline{x}, t) = 0    ,
    \end{align}
    where $\Delta_\overline{x}$ is only taken in $\overline{x}.$ Let $\overline{B}$ be a Brownian motion in $\bbR^d.$ Then $f(\overline{B}_t, t)$ is a Martingale w.r.t. $\mathcal{F}_t.$
\end{thm}
\begin{proof}
    We sketch the proof. We claim that for any $\overline{x}_0 \in \bbR^d$ and for any $t>0,$
    \[\bbE[f(\overline{B}_t + \overline{x}_0, t)] = f(\overline{x}, 0).\] Note that 
    \[p_t(\overline{x}) := \frac{1}{(\sqrt{2\pi t})^d}e^{\frac{-\overline{x}^2}{2t}}\] satisfies the heat equation with the sign flipped. That is, 
    \[\partial_t p(t)- \frac{1}{2}\Delta_{\overline{x}}p_t(\overline{x}) = 0.\] Note that 
    \begin{align*}
        \partial_t\bbE[f(\overline{B}_t  + \overline{x}_0, t)] &= \partial_t \int_{\bbR^d} p_t(\overline{x} - \overline{x}_0)f(\overline{x}, t)\,d\overline{x}\\
        &= \cdots \text{[integrating by parts 3x]}\\
        &= 0
    \end{align*}
    Hence, we get the martingale property with $\overline{B}_s$ instead of $\overline{x}_0$ and $t-s$ instead of $t$:
    \begin{align*}
        \bbE[f(\overline{B}_t + \overline{x}_0, t )\mid \mathcal{F}_s] &= \bbE[f(\overline{B}_t - \overline{B}_s + \overline{B}_s , t-s + s)\mid \mathcal{F}_s]\\
        &= f(\overline{B}_s, s)
    \end{align*}
\end{proof}

\begin{defn}
    Let $f\in C^2(\bbR^d, \bbR).$ We say that $f$ is \textbf{harmonic} if $\Delta f = 0.$ 
\end{defn}
\begin{rem}
    Harmonic functions immediately imply (1) since they are not dependent on time. 
\end{rem}

\begin{exmp}
    Let $f(x,y) = e^x \cos y.$ We have that 
    \[\frac{\partial ^2}{\partial x ^2} = e^x\cos y\]
    \[\frac{\partial ^2}{\partial y^2} = \frac{\partial}{\partial y}(-e^x\sin y) = -e^x\cos y.\] Hence, $f$ is harmonic. We also have that 
    \[|f(x, y)| \leq |e^x \cos x| \leq e^x\] Then if $\overline{B}_t$ is a standard 2D B.M, we know that $f(\overline{B}_t)$ is a martingale w.r.t $\mathcal{F}_t.$

    Let $\tau = \inf\{t \geq 0 \mid |\overline{B}_t - (1,0)| >5\}$ be a stopping time for $\overline{B}_t.$ Suppose the conditions of OST are met. Then 
    \[\bbE[f(\overline{B}_\tau)] = \bbE[f(\overline{B}_0)] = 1\] But 
    \[\bbE[f(\overline{B}_\tau)] >\bbP\{\tau < \infty \} f(\overline{B}_\tau)\]
\end{exmp}




\newpage
\section{Problem Sessions}
\subsection{Monday, Mar 31: Problem Session 1}
When do we run into the issue that $\lim_{n\to \infty}\pi P^n$ does not exist? 
\begin{enumerate}
    \item[(1)] If Period $> 1$
    \item[(2)] If there are multiple recurrence classes that are transient.
\end{enumerate}

Problems:
\begin{enumerate}
    \item Let $X_0, X_1, \dots$ be a Markov chain with state space $S = \{0, 1, 2, 3\}$, and with transition matrix
    \[
    \begin{bmatrix}
        \frac{1}{4} & 0 & \frac{1}{2} & \frac{1}{4} \\
        0 &  \frac{1}{5} & 0 & \frac{1}{5} \\
        0 & 1 & 0 & 0 \\
        \frac{1}{3} & \frac{1}{3} & 0 & \frac{1}{3}
    \end{bmatrix}.
    \]
    A new process is defined by $Z_n = 0$ if $X_n = 0$ or $1$ and $Z_n = X_n$ if $X_n = 2$ or $3$. Find $P(Z_{n+1} = 2 | Z_n = 0, Z_{n-1} = 2)$ and $P(Z_{n+1} = 2 | Z_n = 0, Z_{n-1} = 3)$. Is $Z_n$ a Markov chain?
    \begin{solution}
    \begin{align*}
        \bbP\{Z_{n + 1}= 2 \mid Z_n = 0, Z_{n-1} = 2\} &= \frac{\bbP\{Z_{n + 1} = 2, Z_{n} = 0, Z_{n-1} = 2\}}{\bbP\{Z_n = 0, Z_{n-1 } = 2\}}\\
        &= \frac{\bbP\{Z_{n + 1} = 2, Z_{n} = 0 \mid Z_{n-1} =2\}}{\bbP\{Z_n = 0 \mid Z_{n-1} = 2\}}\\
        &= 0
    \end{align*}
    \begin{align*}
        \bbP\{Z_{n + 1} = 2 \mid Z_n = 0, Z_{n-1} = 3\} &= \frac{\bbP\{Z_{n + 1} = 2, Z_{n} = 0 \mid Z_{n-1} =3\}}{\bbP\{Z_n = 0 \mid Z_{n-1} = 3\}}\\
        &= \frac{\bbP\{X_n = 2, X_n = 0 \mid X_{n-1} = 3\} +\bbP\{X_n = 2, X_n = 1 \mid X_{n-1} = 3\}}{\bbP\{X_n = 0 \mid X_{n-1} =3\} + \bbP\{X_{n} = 1 \mid X_{n-1} = 3\}}\\
        &= \frac{\frac{1}{3}\frac{1}{2} + 0}{\frac{1}{6} + \frac{1}{6}}\\
        &= \frac{1}{4}
    \end{align*}
    Thus, $\{Z_n\}$ is not a Markov chain
    \end{solution}

    \item We repeatedly roll two four-sided dice with numbers 1, 2, 3, and 4 on them. Let $Y_k$ be the sum on the $k$-th roll, $S_n = Y_1 + Y_2 + \dots + Y_n$ be the total of the first $n$ rolls, and $X_n = S_n (\text{ mod } 6)$. Find the transition matrix for $\{X_n\}$.
    \begin{solution}
        $\{X_n\}$ is a Markov process because it only depends on the current state $S_n,$ as you can figure out the next turn only from this, since 
        \[X_{n + 1} = S_{n + 1}\text{ mod } 6 = (S_{n} + Y_{n + 1})\text{ mod } 6= S_n \text{ mod } 6 + Y_{n + 1}\text{ mod } 6 = X_n + Y_{n+1}\text{ mod } 6\] 
        \[P = \begin{bmatrix}
            \frac{3}{16} & \frac{1}{8} & \frac{1}{8} & \frac{1}{8} & \frac{3}{16} & \frac{1}{4}\\
             \frac{1}{4} & \frac{3}{16}& \frac{1}{8} & \frac{1}{8} & \frac{1}{8} & \frac{3}{16} \\
             \frac{3}{16} & \frac{1}{4} & \frac{3}{16}& \frac{1}{8} & \frac{1}{8} & \frac{1}{8} \\
             \frac{1}{8} & \frac{3}{16} & \frac{1}{4} & \frac{3}{16}& \frac{1}{8} & \frac{1}{8} \\
             \frac{1}{8} &\frac{1}{8} & \frac{3}{16} & \frac{1}{4} & \frac{3}{16}& \frac{1}{8} \\
             \frac{1}{8} &\frac{1}{8} &\frac{1}{8} & \frac{3}{16} & \frac{1}{4} & \frac{3}{16} 
        \end{bmatrix}\]
    \end{solution}

    \item Consider a Markov chain with states $S = \{0, \dots, N\}$ and transition probabilities $p(i, i+1) = p$, $p(i, i-1) = q$, for $1 \leq i \leq N-1$, where $p+q = 1$, $0 < p < 1$. Assume $p(0,1) = p(N, N-1) = 1$.
    \begin{enumerate}
        \item Draw a transition diagram for this chain.
        \begin{solution}
        In the following diagram, if you the probability  is above, then it is going to the right:
            \begin{center}
\begin{tikzpicture}[scale=1.2, every node/.style={draw, circle, inner sep=1pt}]
    \node (A) at (-4,0) {0};
    \node (B) at (-2,0) {1};
    \node (C) at (0,0) {$\cdots$}
    \node (D) at (2,0) {$N-1$};
    \node (E) at (4, 0) {$N$};

    \draw[->] (A) -- (B) node[midway, above] {\textcolor{red}{$1$}};
    \draw[->] (B) -- (A) node[midway, below] {\textcolor{red}{$q$}};
    \draw[->] (B) -- (C) node[midway, above] {\textcolor{red}{$p$}};
    \draw[->] (C) -- (B) node[midway, below] {\textcolor{red}{$q$}};
    \draw[->] (C) -- (D) node[midway, above] {\textcolor{red}{$p$}};
    \draw[->] (D) -- (C) node[midway, below] {\textcolor{red}{$q$}};
    \draw[->] (D) -- (E) node[midway, above] {\textcolor{red}{$p$}};
    \draw[->] (E) -- (D) node[midway, below] {\textcolor{red}{$1$}};
\end{tikzpicture}
\end{center}            
        \end{solution}
        \item Is the Markov chain irreducible? 
        \begin{solution}
Let $i,j \in [N],$ then we claim that $i \leftrightarrow j.$ Without loss of generality, suppose that $i < j.$ Suppose $j-i = N.$ Then $p(i,j)\geq p^N >0$ and $p(j,i) \geq q^N >0.$
        \end{solution}
        \item What is the period of this chain? 
        \begin{solution}
            The period has to be $2.$
        \end{solution}
    \end{enumerate}

    \item A taxicab driver moves between the airport $A$ and two hotels $B$ and $C$ according to the following rules. If he is at the airport, he will be at one of the two hotels next with equal probability. If at a hotel, then he returns to the airport with probability $\frac{3}{4}$ and goes to the other hotel with probability $\frac{1}{4}$.
    \begin{enumerate}
        \item Find the transition matrix for the chain.
        \begin{solution}
        \[
            P = \begin{bmatrix}
                0 & \frac{1}{2} & \frac{1}{2}\\
                \frac{3}{4} & 0 & \frac{1}{4}\\
                \frac{3}{4} & \frac{1}{4} & 0
            \end{bmatrix}\]
        \end{solution}
        \item Suppose the driver begins at the airport at time 0. Find the probability for each of his three possible locations at time 2 and the probability he is at hotel $B$ at time 3.
        \begin{solution}
        Squaring the matrix gives
                \[P^2 = \begin{bmatrix}
                    \frac{3}{4} & \frac{1}{8} & \frac{1}{8}\\
                    \frac{3}{16} & \frac{7}{16} & \frac{6}{16}\\
                    \frac{3}{16} & \frac{6}{16} & \frac{7}{16}
                \end{bmatrix}\]
                and so 
                \[p^2(A,A) = \frac{3}{4}, \quad p^2(B,A) = \frac{3}{16}, \quad p^2(C,A) = \frac{3}{16}\]
            Similarly, 
            \[p^3(B,A) = \frac{13}{32}\]
        \end{solution}
    \end{enumerate}

    \item At time $n = 0$, two ladybirds are placed at vertices $i$ and $j$ of a regular hexagon, whose vertices are labeled $1, \dots, 6$. At time $n = 1$, each of them moves, independently of the other, to one of the two adjacent vertices with probability $\frac{1}{2}$, and so on at each time $n = 2, 3, \dots$.
    \begin{enumerate}
        \item Denote $X_n$ the distance between the two ladybirds at time $n \geq 0$, i.e., the minimum number of edges between them. Find the transition matrix for $\{X_n\}$.
        \begin{solution}
            $S = \{0, 1, 2, 3\}$
            \[P = \begin{bmatrix}
                \frac{1}{2} & 0 & \frac{1}{2} & 0\\
                0 & \frac{3}{4} & 0 & \frac{1}{4}\\
                \frac{1}{4}& 0 & \frac{3}{4} & 0\\
                0 & \frac{1}{2} & 0 & \frac{1}{2}
            \end{bmatrix}\]
        \end{solution}
        \item Identify the communication classes. Are they recurrent or transient?
        \[C_1 = \{0,2\}, \quad C_2 = \{1,3\}.\] Both are recurrent.
    \end{enumerate}

    \item Find the invariant (stationary) distributions for the following Markov chains with given transition matrices:
    (a)
    \[\begin{bmatrix}
        \frac{1}{2} & \frac{2}{5} & \frac{1}{10}\\
        \frac{1}{5} & \frac{1}{2} & \frac{3}{10}\\
        \frac{1}{10} & \frac{3}{10} & \frac{3}{5}
    \end{bmatrix}\]
    \begin{solution}
        This will be the only time I type out a full solution to this. 
        We need to solve for the normalized eigenvector of $P^T$ corresponding to $\lambda = 1.$ It suffices to find $\pi^T$ such that 
        \[10 P^T - 10\pi^T = 0\] That is, we need to find the eigen basis of
        \begin{align*}
            E_{10}(10P^T) &= 
            \begin{pmatrix}
            5 & 2 & 1\\
            4 & 5 & 3\\
            1 & 3 & 6
            \end{pmatrix} - 10I\\
        &= \begin{pmatrix}
            -5 & 2 & 1\\
            4 & -5 & 3\\
            1 & 3 & -4
            \end{pmatrix}\\
            &\simeq 
            \begin{pmatrix}
            -20 & 8 & 4\\
            20 & -25 & 15\\
            20 & 60 & -80
            \end{pmatrix}\\
            &\simeq
            \begin{pmatrix}
            -20 & 8 & 4\\
            0 & -17 & 19\\
            0 & 68 & -76
            \end{pmatrix}\\
            &\simeq
            \begin{pmatrix}
            1 & -\frac{2}{5} & - \frac{1}{5}\\
            0 & 1 & -\frac{19}{17}\\
            0 & -68 & 76
            \end{pmatrix}\\
            &\simeq
            \begin{pmatrix}
            1 & -\frac{2}{5} & - \frac{1}{5}\\
            0 & 1 & -\frac{19}{17}\\
            0 & -68 & 76
            \end{pmatrix}\\
            &\simeq
            \begin{pmatrix}
            1 & 0 & - \frac{11}{17}\\
            0 & 1 & -\frac{19}{17}\\
            0 & 0 & 0
            \end{pmatrix}
        \end{align*}
        Thus, 
        \[\pi_1^T = \frac{11}{17}\pi_3^T, \qquad \pi_2^T = \frac{19}{17}\pi_3^T, \qquad \pi_1^T + \pi_2^T + \pi_3^T = 1\] Solving:
        \begin{align*}
            \left[\begin{array}{ccc | c}
               1  & 0 &-\frac{11}{17} & 0 \\
               0  & 1 &-\frac{19}{17} & 0\\
               1 & 1 & 1 & 1
            \end{array}\right] &\simeq
            \left[\begin{array}{ccc | c}
               1  & 0 &-\frac{11}{17} & 0 \\
               0  & 1 &-\frac{19}{17} & 0\\
               0 & 0 & \frac{28}{17} & 1
            \end{array}\right]\\
            &\simeq
            \left[\begin{array}{ccc | c}
               17  & 0 &-11 & 0 \\
               0  & 17 &-19 & 0\\
               0 & 0 & 28 & 47
            \end{array}\right]\\
            &\simeq
            \left[\begin{array}{ccc | c}
               1  & 0 &0 & \frac{11}{47} \\
               0  & 1 &0 & \frac{19}{47 }\\
               0 & 0 & 1 & \frac{17}{47}
            \end{array}\right]
        \end{align*}
        So then 
        \[\pi = (\frac{11}{47}, \frac{19}{47}, \frac{17}{47})\]
    \end{solution}
    (b)
    \[
    \begin{bmatrix}
        \frac{1}{2} & \frac{2}{5} & \frac{1}{10} \\
        \frac{3}{10} & \frac{2}{5} & \frac{3}{10} \\
        \frac{1}{5} & \frac{1}{5} & \frac{3}{5}
    \end{bmatrix}.
    \]
    \begin{solution}
        \pi = (\frac{1}{3}, \frac{1}{3}, \frac{1}{3})
    \end{solution}
\end{enumerate}

\newpage
\subsection{Monday, Apr 7: Problem Session 2}
\begin{enumerate}
    \item A queen can move any number of squares horizontally, vertically, or diagonally on an $8 \times 8$ chessboard. Let $\{X_n\}$ be the sequence of squares that results if we pick one of the queenâs legal moves uniformly at random. Find
        \begin{enumerate}
            \item the stationary distribution and
    \begin{solution}
        We use Example 1.12. First, consider that the following 4x4 grid of the degrees for each positions on the upper left of the board:
        \begin{bmatrix}
            21 & 21 & 21 & 21\\
            21 & 23 & 23 & 23\\
            21 & 23 & 25 & 25\\
            21 & 23 & 25 & 27
        \end{bmatrix}
        Thus, 
        \[\pi_{(0,0)} = \frac{\deg (1,1)}{2|E|} = \frac{21}{1456}\]
    \end{solution}
            \item the expected number of moves needed to return to the bottom left corner when we start there.
        \begin{solution}
            If we define 
            \[T_{i,j} = \inf[n : X_n = (i,j) \mid X_0 = (i,j)],\]
            then by Example 1.12, 
            \[\bbE[T_{0,0}] = \frac{1}{\pi_{0,0}} = \frac{1456}{21}\]
        \end{solution}
        \end{enumerate}

    \item Let $\{X_n\}$ be the random walk on $\{-10, -9, \ldots, 9, 10\}$ with reflected boundary, i.e., the Markov chain with transition probabilities
        $$
        p(x, x+1) = p(x, x-1) = \frac{1}{2}, \quad \forall x \in \{-9, \ldots, 9\}, \quad p(-10, -9) = p(10, 9) = 1.
        $$
        Assume that $X_0 = 0$ and let
        $$
        T = \min \{ n \geq 1 : X_n = 1 \}.
        $$
        Find the expected number of times that the walk hits 0 before time $T$, i.e., compute
        $$
        \mathbb{E}\left[ \#\{n \in \{0, \ldots, T\} : X_n = 0\} \right].
        $$
        (Hint: use the strong Markov property applied at the times for which $X_n = 0$).
    \begin{solution}
        Call 
        \[T_1 = \inf\{n  : X_n = 1 \mid X_0 = 0\}\] Call
        \[K(i, j) = \sum_{n=1}^j \mathbbm{1}_{X_n = 1}\]
        Then using the law of total expectation:
        \begin{align*}
            \bbE[K(0, T_1)] &= \bbE[\bbE[K(0,T_1) \mid X_1]]\\
            &= \frac{1}{2}(\bbE[K(0, T_1)\mid X_1 = -1] + 1) + \frac{1}{2}(\bbE[K(0,T_1) \mid X_1 = 1] +1)\\
            &\text{By definition:}\\
            &= \frac{1}{2}(\bbE[K(0, T_1)\mid X_1 = -1] + 1) + \frac{1}{2}(0 +1)\\
            &\text{Strong Markov Property:}\\
            &= \frac{1}{2}(\bbE[K(T_0, T_1)] + 1) + \frac{1}{2}(0 +1)\\
            &= \frac{1}{2} + \frac{1}{2}(\bbE[K(0, T_1)] +1)
        \end{align*}
        Solving:
        \[\bbE[K(0, T_1)] = 2.\] 
    \end{solution}

    \item Consider the numbers $\{1, 2, 3, \ldots, 12\}$ written around a ring as they usually are on a clock. Consider a Markov chain $\{X_n\}$ that at any point jumps with equal probability to the two adjacent numbers.
        \begin{enumerate}
            \item What is the expected number of steps that $\{X_n\}$ will take to return to its starting position?
            \begin{solution}
            Suppose WLOG $X_n = 12.$ Then
                $2|E| = 24$ and $\deg 12 = 2.$ Thus, if 
                \[T_{12} = \inf\{n>0 : X_n = 12 \mid X_0 = 12\},\] then
                \[\bbE[T_{12}] = \frac{1}{\pi_{12}} = \frac{2|E|}{\deg(12)} = \frac{24}{2} = 2.\]
            \end{solution}
            \item What is the probability that $\{X_n\}$ will visit all the other states before returning to its starting position?
            \begin{solution}
                We will use the law of total probability. Again, WLOG, assume $X_0 = 12.$ Define 
                \[E_{12} = \text{running through everything before returning to 12}\]
                \[\bbP\{E_{12}\} = 2(\bbP\{E_{12} \mid X_1 = 1\}\bbP\{X_1 = 1\})\]
                Thus, we can make 
                $\bbP\{E_{12} \mid X_1 = 1\}$ a gambler's ruin problem! 
\begin{figure}[H]
                    \centering
                    \includegraphics[width=0.5\linewidth]{Images/MarkovProof.png}
                    \caption{Gambling With a Clock}
                \end{figure}
                                
                the probability of reaching 12 on the left is given by $1 - P_{11} = 1 - \frac{11}{12} = \frac{1}{12}$
            \end{solution}
        \end{enumerate}

    \item Before you are six light bulbs (all off), numbered $\{1, 2, \ldots, 6\}$. At each time $n \geq 1$, you roll a fair six-sided die and flip the switch of the bulb corresponding to the number you have rolled, turning it on if it is off, and off if it is on. What is the expected number of rolls needed until every light bulb is turned on?
    

    \item Find the probability that, in the process of repeatedly flipping a fair coin, one will encounter a run of 5 heads in a row before one encounters a run of 2 tails in a row.
    \begin{solution}
        
    \end{solution}

    \item In a game similar to three card monte, the dealer places three cards on the table: the queen of spades and two red cards. The cards are placed in a row, and the queen starts in the center; the card configuration is thus $RQR$. The dealer proceeds to move. With each move, the dealer randomly switches the center card with one of the two edge cards (so the configuration after the first move is either $RRQ$ or $QRR$). What is the probability that, after 2025 moves, the center card is the queen?
\end{enumerate}



\newpage
\subsection{Monday, Apr 14: Problem Session 3}
\begin{enumerate}
\item
Let \(\{X_n\}\) be a Markov chain with state space \(S=\{0,1,2,\ldots\}\). For each of the following transition probabilities, state whether the chain is positive recurrent, null recurrent, or transient. If it is positive recurrent, give the stationary distribution.

\begin{enumerate}[(a)]
    \item \(p(x,x+1)=\frac{5}{7}\), \(p(x,0)=\frac{2}{7}\).
\begin{solution}
    We claim that $\{X_n\}$ is positive recurrent. Indeed, we can see that the stationary distribution must satisfy
    \[\pi_0 = \frac{2}{7}(\sum_{n=0}^\infty \pi_n), \pi_1 = \frac{5}{7}\pi_0, \quad \dots, \pi_n = (\frac{5}{7})^n \pi_0, \quad \sum_{n=0}^\infty \pi_n = 1.\]
    Then 
    \[\pi_n = \left(\frac{5}{7}\right)^n \frac{2}{7}\] is a valid stationary distribution.

\end{solution}
    
    \item \(p(x,0)=\frac{x+1}{x+2}\), \(p(x,x+1)=\frac{1}{x+2}\).
\begin{solution}
    Let $\tau_0 := \{n >0 | X_n = 0 \}.$ Then 
    \[\bbP\{\tau_0  = \infty \mid X_0 = 0\} \geq \prod_{k=1}^\infty \frac{1}{(k+2)} = \lim_{n\to \infty}\frac{1}{(n+2)!} = 0.\] Thus, $\{X_n\}$ is recurrent. Let's check for a stationary distribution!
    
\end{solution}
    \item \(p(x,x+1)=\frac{x+1}{x+2}\), \(p(x,0)=\frac{1}{x+2}\).
    
    \item \(p(x,0)=\frac{1}{x^2+2}\), \(p(x,x+1)=\frac{x^2+1}{x^2+2}\).
\end{enumerate}

\item
Let \(\{X_n\}\) be a biased random walk on \(\mathbb{Z}\) with probability \(p>1/2\) to move to the right, i.e., the transition probabilities are
\[
p(x,x-1)=1-p, \quad p(x,x+1)=p, \quad \forall x\in\mathbb{Z}.
\]
Assume that \(X_0=0\).

\begin{enumerate}[(a)]
    \item Find \(\mathbb{P}[X_n=0]\). \textbf{(Hint:} \(X_n=0\) if and only if we have the same number of \(+1\) steps as \(-1\) steps before time \(n\).)
\begin{solution}
    \[p^{2n}(0,0) = \binom{2n}{n}p^n (1-p)^n\]
\end{solution}
    
    \item For \(K\geq 1\), let \(T_K=\min\{n\geq 1:X_n=K\}\). Find \(\mathbb{P}[X_n\geq 0,\,\forall n=0,\ldots,T_K]\).
\begin{solution}
    This is a shifted gambler's ruin. We can think of it as shifting it by $1$ to the right and the probability of winning $K+1$ dollars before losing it all (starting with one dollar). We have found that 
    \[P_1 = \frac{1 - (\frac{1-p}{p})}{1 - (\frac{1-p}{p})^{K+1}}\]
\end{solution}
    
    \item Find the probability that \(X_n\) returns to 0 after time \(T_K\).
\begin{solution}
    Let $A = \{\exists n >T_K \mid X_n = 0\}.$ Then by the strong Markov property and the law of total probability, if we call
    \[\alpha(k):= \bbP\{A \mid X_0 = k\},\] then
\begin{align*}
   \alpha(k) &= \alpha(k-1)\bbP\{X_1 = K-1\} + \alpha(k+1)\bbP\{X_1 = K+1\}\\
   &= \alpha(k-1)(1-p) + \alpha(k+1)p
\end{align*}
Solving gives 
\[\alpha = \frac{1 \pm \sqrt{1 - 4p(1-p)}}{2p} = \frac{1 \pm (1 - 2p)}{2p} \in \{1, \frac{1-p}{p}\}.\] Thus, 
\[\alpha(n) = \lambda_1 + \lambda_2(\frac{1-p}{p})^n.\] We know that $\alpha(0) = 1.$ Thus, 
\[\lambda_1 + \lambda_2 = 1\] Moreover, we know that 
\[\lim_{n\to \infty}\alpha(n) = 0 = \lambda_1.\] Thus, $\lambda_2 = 1$ and so 
\[\alpha(K) = (\frac{1-p}{p})^K.\]
\end{solution}
    
    \item Find the probability that \(X_n\geq 0\) for all \(n=0,\ldots,T_K\) and \(X_n\) returns to 0 after time \(T_K\).
\begin{solution}
    By the strong Markov Property, these are independent, so simply multiply the results from (ii) and (iii)
\end{solution}
\end{enumerate}

\item
Consider the Markov chain with state space \(\mathbb{Z}\) whose transition probabilities are given by \(p(x,x-1)=2/3\) and \(p(x,x+2)=1/3\) (\(p(x,y)=0\) for all other \(y\)). Determine whether this Markov chain is positive recurrent, null recurrent, or transient. \textbf{(Hint:} use a calculation with the binomial distribution similar to what we did for random walk on \(\mathbb{Z}\).)
\begin{solution}
\begin{align*}
p^{3k}(0,0) &= \binom{3k}{k}(\frac{1}{3})^k(\frac{2}{3})^{2k}\\  &= \frac{(3k)!}{(k)! (2k)!}(\frac{1}{3})^k(\frac{2}{3})^{2k}     \\
&\sim \frac{\sqrt{6\pi k} (\frac{3k}{e})^{3k}}{\sqrt{2\pi k}(\frac{k}{e})^k \sqrt{4\pi k}(\frac{2k}{e})^{2k}}(\frac{1}{3})^k(\frac{2}{3})^{2k} \\
&= \frac{\sqrt{6\pi k} (\frac{3k}{e})^{3k}}{\sqrt{2\pi k}(\frac{k}{e})^k \sqrt{4\pi k}(\frac{2k}{e})^{2k}}(\frac{1}{3})^k(\frac{2}{3})^{2k}\\
&= \sqrt{\frac{3}{4\pi k}}
\end{align*}
We have that 
\[\sum_{k=0}^\infty p^{3k}(0,0)  = \infty,\] and so the process is recurrent. It is null recurrent since $p^n(0,0) \to 0.$

\end{solution}

\item
The \emph{infinite binary tree} is the graph \(T\) whose vertex set \(V(T)\) consists of the empty sequence \(\emptyset\) together with all \(k\)-tuples of the form \((a_1,a_2,\ldots,a_k)\), where \(k\in\mathbb{N}\) and \(a_j\in\{0,1\}\) for \(j\in\{1,\ldots,k\}\). There are edges joining \(\emptyset\) to (0) and (1) and edges joining \((a_1,\ldots,a_k)\) to \((a_1,\ldots,a_k,0)\) and \((a_1,\ldots,a_k,1)\) for each \((a_1,\ldots,a_k)\), see the figure below. Let \(\{X_n\}\) be the random walk on \(T\). Compute
\[
\mathbb{P}[X_n=\emptyset\text{ for some }n\geq 1\,|\,X_0=\emptyset],
\]
and conclude that \(\{X_n\}\) is transient. \textbf{(Hint:} let \(H_n\) be the "height" for \(X_n\), i.e., if \(X_n=\emptyset\) then \(H_n=0\) and if \(X_n=(a_1,\ldots,a_k)\) then \(H_n=k\). Relate \(H_n\) to a biased random walk.)

\end{enumerate}






















\end{document}