\documentclass[11pt]{article}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{automata, positioning}
% NOTE: Add in the relevant information to the commands below; or, if you'll be using the same information frequently, add these commands at the top of paolo-pset.tex file. 
\newcommand{\name}{Agust√≠n Esteva}
\newcommand{\email}{aesteva@uchicago.edu}
\newcommand{\classnum}{23500}
\newcommand{\subject}{Markov Chains, Martingales, and Brownian Motion}
\newcommand{\instructors}{Stephen Yearwood}
\newcommand{\assignment}{Problem Set 3}
\newcommand{\semester}{Spring 2025}
\newcommand{\duedate}{04/18/2025}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bD}{\mathbf{D}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bG}{\mathbf{G}}
\newcommand{\bH}{\mathbf{H}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\bJ}{\mathbf{J}}
\newcommand{\bK}{\mathbf{K}}
\newcommand{\bL}{\mathbf{L}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bN}{\mathbf{N}}
\newcommand{\bO}{\mathbf{O}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bR}{\mathbf{R}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\Vol}{\text{Vol}}

%% blackboard bold math capitals
\newcommand{\bbA}{\mathbb{A}}
\newcommand{\bbB}{\mathbb{B}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbD}{\mathbb{D}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbF}{\mathbb{F}}
\newcommand{\bbG}{\mathbb{G}}
\newcommand{\bbH}{\mathbb{H}}
\newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbJ}{\mathbb{J}}
\newcommand{\bbK}{\mathbb{K}}
\newcommand{\bbL}{\mathbb{L}}
\newcommand{\bbM}{\mathbb{M}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\bbO}{\mathbb{O}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbS}{\mathbb{S}}
\newcommand{\bbT}{\mathbb{T}}
\newcommand{\bbU}{\mathbb{U}}
\newcommand{\bbV}{\mathbb{V}}
\newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bbY}{\mathbb{Y}}
\newcommand{\bbZ}{\mathbb{Z}}

%% script math capitals
\newcommand{\sA}{\mathscr{A}}
\newcommand{\sB}{\mathscr{B}}
\newcommand{\sC}{\mathscr{C}}
\newcommand{\sD}{\mathscr{D}}
\newcommand{\sE}{\mathscr{E}}
\newcommand{\sF}{\mathscr{F}}
\newcommand{\sG}{\mathscr{G}}
\newcommand{\sH}{\mathscr{H}}
\newcommand{\sI}{\mathscr{I}}
\newcommand{\sJ}{\mathscr{J}}
\newcommand{\sK}{\mathscr{K}}
\newcommand{\sL}{\mathscr{L}}
\newcommand{\sM}{\mathscr{M}}
\newcommand{\sN}{\mathscr{N}}
\newcommand{\sO}{\mathscr{O}}
\newcommand{\sP}{\mathscr{P}}
\newcommand{\sQ}{\mathscr{Q}}
\newcommand{\sR}{\mathscr{R}}
\newcommand{\sS}{\mathscr{S}}
\newcommand{\sT}{\mathscr{T}}
\newcommand{\sU}{\mathscr{U}}
\newcommand{\sV}{\mathscr{V}}
\newcommand{\sW}{\mathscr{W}}
\newcommand{\sX}{\mathscr{X}}
\newcommand{\sY}{\mathscr{Y}}
\newcommand{\sZ}{\mathscr{Z}}


\renewcommand{\emptyset}{\O}

\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\norm}[1]{\lVert #1 \rVert}
\newcommand{\sm}{\setminus}


\newcommand{\sarr}{\rightarrow}
\newcommand{\arr}{\longrightarrow}

% NOTE: Defining collaborators is optional; to not list collaborators, comment out the line below.
%\newcommand{\collaborators}{Alyssa P. Hacker (\texttt{aphacker}), Ben Bitdiddle (\texttt{bitdiddle})}

\input{paolo-pset.tex}

% NOTE: To compile a version of this pset without problems, solutions, or reflections, uncomment the relevant line below.

%\excludeversion{problem}
%\excludeversion{solution}
%\excludeversion{reflection}

\begin{document}	
	
	% Use the \psetheader command at the beginning of a pset. 
	\psetheader

\section*{Problem 1}
Consider the queuing model as discussed in class (section 1.2 of the week 3 notes on canvas).

\begin{enumerate}[label=(\alph*)]
    \item For the transient case (i.e., when \(q<p\)) compute
    \[
    \alpha(x):=\mathbb{P}\{\text{starting at $x$ the queue ever reaches state 0}\}.
    \]
\begin{solution}
    Let $x \geq 0,$ We use the law of total probability and the Markov property to compute:
\begin{align*}
    \alpha(x) &= \alpha(x-1) q(1-p) + \alpha(x)(pq + (1-q)(1-p)) + \alpha(x + 1)p(1-q)\\
    &= \alpha(x-1) q(1-p) + \alpha(x)\big(1 - p(1-q) - q(1-p)\big) + \alpha(x + 1)p(1-p)\\
    &= \alpha(x-1) q(1-p) + \alpha(x) - \alpha(x)\big(p(1-q) + q(1-p)\big) + \alpha(x + 1)p(1-q)\\
    &= \alpha(x-1) \frac{q(1-p)}{p(1-q) + q(1-q)} + \alpha(x + 1) \frac{p(1-q)}{p(1-q) + q(1-p)}\\
    &= \alpha(x-1)A + \alpha(x+1)B
\end{align*}
So then after some algebra and using the general formula that 
\[\alpha_{\pm} = \frac{1 \pm \sqrt{1 - 4AB}}{2A} \implies \alpha \in \{1, \frac{q(1-p)}{p(1-q)}\}\] Thus, 
\[\alpha(x) = \lambda_1  + \lambda_2\left(\frac{q(1-p)}{p(1-q)}\right)^x\]
We have two boundary conditions:
\[\alpha(0) = 1, \qquad \lim_{n \to \infty}\alpha(n) = 0\] From the first, we see that $\lambda_1 + \lambda_2 = 1.$ From the second, we see that since $q<p,$ then 
\[q< p \iff q - qp < p - qp \iff q(1-p) < p(1-q) \iff \frac{q(1-p)}{p(1-q)} <1 \implies \left(\frac{q(1-p)}{p(1-q)}\right)^n \to0,\] and so $\lambda_1 = 0.$ Thus, $\lambda_2 = 1$ and so 
\[\alpha(x) = \left(\frac{q(1-p)}{p(1-q)}\right)^x\]
\end{solution}
    
    \item For which values of \(p,q\) is the chain null/positive recurrent? In the positive recurrent case, give the stationary distribution.
\begin{solution}
    The chain is positive recurrent if and only if a stationary distribution exists, so it suffices to find a condition for which the stationary distribution exists. A stationary distribution must satisfy 
    \[\pi_0 = (1-p)\pi_0 + q(1-p)\pi_1\]
    \[\pi_1 = p \pi_0 + \big(pq +(1-p)(1-q)\big) \pi_1 + q(1-p)\pi_2\]
    \[\pi_n = p(1-q) \pi_{n-1} + \big(pq + (1-p)(1-q)\big)\pi_n + q(1-p)\pi_{n+1}, \quad n\geq 2\]
    We have already solved the recursive relation. 
    \[\pi_n = \lambda_1 + \lambda_2\left(\frac{p(1-q)}{q(1-p)}\right)^n\]
    Solving for the constants, we see that 
    \[1 = \sum_{n=0}^\infty \pi_n = \sum_{n=1}^\infty \lambda_1 + \lambda_2\left(\frac{p(1-q)}{q(1-p)}\right)^n \implies \lambda_1 = 0.\] Thus, we see that 
    \[\lambda_2\sum_{n=0}^\infty \left(\frac{p(1-q)}{q(1-p)}\right)^n < \infty \iff p < q.\] Thus, the chain is null recurrent if, and only if, $p = q.$ It is positive recurrent if $p<q.$ From the above, we see that if $p<q,$ then the series is geometric and thus 
    \[1 = \lambda_2\sum_{n=0}^\infty \left(\frac{p(1-q)}{q(1-p)}\right)^n = \frac{\lambda_2}{1 - (\frac{p(1-q)}{q(1-p)})} \implies \lambda_2 = 1 - \frac{p(1-q)}{q(1-p)}.\] Thus, 
    \[\pi_n = (1 - \frac{p(1-q)}{q(1-p)})\left(\frac{p(1-q)}{q(1-p)}\right)^n\]
\end{solution}
    
    \item What is the average length of the queue in equilibrium (i.e., the long-run average length of the queue)?
    \begin{solution}
        Clearly, if $q\geq p,$ then the average length is infinity. If $q<p,$ then we see that 
\begin{align*}
\bbE[\pi] &= \sum_{n=0}^\infty n\pi_n\\ &= (1 - \frac{p(1-q)}{q(1-p)})\sum_{n=0}^\infty n\left(\frac{p(1-q)}{q(1-p)}\right)^n\\ &= (1 - \frac{p(1-q)}{q(1-p)})\left(\frac{\frac{p(1-q)}{q(1-p)}}{(1 - \frac{p(1-q)}{q(1-p)})^2}\right)\\ &= \frac{\frac{p(1-q)}{q(1-p)}}{1 - \frac{p(1-q)}{q(1-p)}}\\ &= \frac{p(1-q)}{q-p}    
\end{align*}

    \end{solution}
\end{enumerate}


\newpage
\section*{Problem 2}
Consider the following Markov chain with state space \(S=\{0,1,\ldots\}\). A sequence of positive numbers \(p_{1},p_{2},\ldots\) is given with \(\sum_{i=1}^{\infty}p_{i}=1\). Whenever the chain reaches state 0 it chooses a new state according to the \(p_{i}\). Whenever the chain is at a state other than 0 it proceeds deterministically, one step at a time, toward 0. In other words, the chain has transition probability
\[
p(x,x-1)=1,\quad x>0, \quad p(0,x)=p_{x},\quad x>0.
\]
This is a recurrent chain since the chain keeps returning to 0. Under what conditions on the \(p_{x}\) is the chain positive recurrent? In this case, what is the limiting probability distribution \(\pi\)? \textit{[Hint: it may be easier to compute \(\mathbb{E}(T)\) directly where \(T\) is the time of first return to 0 starting at 0.]}
\begin{solution}
Let $x\in S,$ then define
    \[T_x:= \min\{n\geq 1 :X_n = x \mid X_0 = x\}.\] Clearly, since the first move doesn't matter (unless $x = 0$), we have that $\bbE[T_x] = 1 + \bbE[\bbE[T_x \mid X_2]].$ Evidently, $\bbE[T_x \mid X_2 = x] = 2.$ But since the chain resets every two moves, then by the markov property
    \[\bbE[T_x \mid X_2 = y] = \bbE[T_x \mid X_2 = z] = \bbE[T_x \mid X_0 = x], \quad y\neq z\neq x.\] Thus, for any $x\in S$ such that $x\neq 0,$ we have that
    \begin{align*}
        \bbE[T_x] &= 1 + \bbE[\bbE[T_x \mid X_2]]\\
        &= 1 + (1 + \bbE[T_x \mid X_2 = 1])p_1  + \dots + (1 + \bbE[T_x \mid X_2 = x-1])p_{x-1} + (1)p_x + (1 + \bbE[T_x \mid X_2 =x+1])p_{x+1} + \cdots\\
        &= 1 + \sum_{n=1}^\infty p_n + \bbE[T_x \mid X_0 = x]\sum_{n\neq x} p_n\\
        &= 2 + \bbE[T_x \mid X_0 = x](1-p_x)
    \end{align*}
    Thus, \[\bbE[T_x \mid X_0 = x] = \frac{2}{p_x}\]
    Which is finite as long as $p_x >0.$ For $x = 0,$ we have that 
    \[\bbE[T_0 \mid X_0 = 0] = 2.\] Thus, $\bbE[T_x \mid X_0 = x] < \infty$ as long as $p_x < \infty$ for all $x\in S.$ Thus, if this condition is met, then 
    \[\pi_x = \begin{cases}
        \frac{p_x}{2}, \quad x\geq 1\\
        \frac{1}{2}, \quad \:\:x = 1
    \end{cases}\]
\end{solution}

\section*{Problem 3 (Optional)}
A \textit{diagonal lattice path} is a "curve" in the plane made up of line segments that go from a point \((i,j)\) to either \((i+1,j+1)\) (an up step) or \((i+1,j-1)\) (a down step). A \textit{Dyck path of length \(2n\)} is a diagonal lattice path from \((0,0)\) to \((2n,0)\) that does not go below the \(x\)-axis.

\begin{enumerate}[label=(\alph*)]
    \item Prove that the diagonal lattice paths from \((0,0)\) to \((2n,0)\) that go below the \(x\)-axis are in bijection with the diagonal lattice paths from \((0,0)\) to \((2n,-2)\). \textit{(Hint: Given a path P from \((0,0)\) to \((0,2n)\) that goes below the \(x\)-axis, consider the first edge \(e\) that crosses \(y=0.\) Switch the directions of every edge after \(e\), i.e., an up edge becomes down, and a down edge becomes up.)}
    
    \item Show that the number of Dyck paths from \((0,0)\) to \((2n,0)\) is given by
    \[
    C_{n}:=\frac{1}{n+1}\binom{2n}{n}.
    \]
    The quantity \(C_{n}\) is called the \(n^{\text{th}}\) \textit{Catalan number}, and appears very frequently in enumerative combinatorics.
    
    \item Let \(\{X_{n}\}\) be a simple random walk on \(\mathbb{Z}\) starting at \(0\), and let \(T:=\min\{n\geq 1:X_{n}=0\}\).
    \begin{enumerate}[label=(\roman*)]
        \item Let \(E_{k}:=\{T=2k\}\) be the event that the walk first returns to \(0\) at time \(2k\). Use the previous parts to find \(\mathbb{P}\{E_{k}\}\) in terms of \(k\).
        \item Use Stirling's approximation to show that \(E[T]=\infty\).
    \end{enumerate}
\end{enumerate}

\section*{Problem 4 (20 points)}
For each of the following Markov chains, determine whether the chain is positive recurrent, null recurrent, or transient. In the positive recurrent case, find the stationary distribution.

\begin{enumerate}[label=(\alph*)]
    \item For \(x\in\mathbb{Z}\) with \(x\geq 0\), \(p(x,0)=(x+1)/(x+2)\) and \(p(x,x+1)=1/(x+2)\) (\(p(x,y)=0\) for all other \(y\)).
\begin{solution}
We claim that this process is positive recurrent. It suffices to find a stationary distribution. The stationary distribution must satisfy
\[\pi_0 = \sum_{n=0}^\infty \frac{n+1}{n+2}\pi_n, \quad \pi_n = \frac{1}{(n+1)!}\pi_0, \quad \sum_{n=0}^\infty \pi_n = 1.\] From the second and third, we see that 
\begin{align*}
    1 &= \sum_{n=0}^\infty \pi_n\\
    &= \sum_{n=0}^\infty \frac{1}{(n+1)!}\pi_0\\
    &= \pi_0(e-1)
\end{align*}
and so $\pi_0 = (e-2)!.$ Thus, 
\[\pi_n = \frac{1}{(n+1)!}\frac{1}{(e-1)}\]
\end{solution}
    
    \item For \(x\in\mathbb{Z}\) with \(x\geq 0\), \(p(x,0)=1/(x+2)^{2}\) and \(p(x,x+1)=1-1/(x+2)^{2}\) (\(p(x,y)=0\) for all other \(y\)).
\end{enumerate}

\section*{Problem 5 (20 points)}
Consider the Markov chain with state space \(S=\{0,1,2,\cdots\}\) with transition probabilities
\[
p(0,0)=\frac{2}{3},\quad p(0,1)=\frac{1}{3},
\]
\[
p(x,x-1)=\frac{2}{3},\quad p(x,x+1)=\frac{1}{3},\quad x>0.
\]

\begin{enumerate}[label=(\alph*)]
    \item Show that this is positive recurrent by giving the invariant probability.
    \begin{solution}
A stationary probability satisfies the recursive relation
\[\pi_n = \frac{1}{3}\pi_{n-1} + \frac{2}{3}\pi_{n+1}.\] Then 
\[\alpha = \frac{1\pm \sqrt{1 - 4(\frac{1}{3}\cdot\frac{2}{3})}}{\frac{4}{3}} \in \{1, \frac{1}{2}\}.\]
Thus, 
\[\pi_n = \lambda_1 + \lambda_2\frac{1}{2^n}.\] We have that 
\[1 = \sum_{n=0}^\infty \pi_n = \sum_{n=0}^\infty \lambda_1 + \lambda_2\sum_{n=0}^\infty \frac{1}{2^n}\implies \lambda_1 = 0, \lambda_2 = \frac{1}{2}.\] Thus, 
\[\pi_n = \frac{1}{2^{n+1}}.\]
    \end{solution}
    
    \item For \(x>0\), let \(E_{x}\) denote the expected number of steps in the chain until it reaches the origin assuming that \(X_{0}=x\). Find \(E_{1}\). \textit{(Hint: first consider the expected return time starting at the origin and write \(E_{1}\) in terms of this.)}
\begin{solution}
    From above, since $\pi_0 = \frac{1}{2},$ then 
    \[E_0 = 2.\] However, we can also write 
    \[E_0 = \bbE[n >0: X_n = 0 \mid X_0 = x] = \bbE[\bbE[n>0 : X_n = 0 \mid X_1]] = (1 + 0)\frac{2}{3} + (1 + E_1)\frac{1}{3} = 1 + \frac{1}{3}E_1.\] Thus, 
    \[1 + \frac{1}{3}E_1 = 2 \implies E_1 = 3.\]
\end{solution}
    
    \item Find \(E_{x}\) for all \(x>0\).
\begin{solution}
    \[3 = E_1 = 1  + \frac{1}{3}E_{2} \implies E_2 = 6.\] In general, for $x \geq 2,$ 
    \[E_2 = 1 + \frac{2}{3}E_{1} + \frac{1}{3}E_{x+1}\implies 3E_n - 3 - 2E_{n-1} = E_{n+1}\]
\end{solution}
    
    \item Suppose we modify the chain so that
    \[
    p(0,1)=\frac{1}{4},\quad p(0,2)=\frac{1}{4},\quad p(0,3)=\frac{1}{4},\quad p(0,4)=\frac{1}{4}.
    \]
    The transitions for \(x>0\) are the same as before. Let \(\pi\) denote the invariant probability for this new chain. Find \(\pi(0)\).
    
    \item Find \(\pi(1)\) for this new chain.
\end{enumerate}

\section*{Problem 6 (10 points)}
Let $\{Y_j\}_{j\in\bbN}$ be independent, identically distributed integer-valued random variables which are not identically equal to zero. For a given value of \(X_{0}\in\mathbb{Z}\), let \(X_{n}=X_{0}+\sum_{j=1}^{n}Y_{j}\) for each \(n\geq 1\). We view \(\{X_{n}\}\) as a Markov chain taking values in \(\mathbb{Z}\). Show that \(\{X_{n}\}\) does not have a stationary distribution. Conclude that \(\{X_{n}\}\) is either null recurrent or transient, not positive recurrent. \textit{(Hint: assume for contradiction that there is a stationary distribution \(\pi\), and look at a value of \(n\in\mathbb{Z}\) such that \(\pi(n)\) is maximal).}

\section*{Problem 7 (Optional)}
In this exercise, we will establish Stirling's formula. Let \(X_{1},X_{2},\ldots\) be independent Poisson random variables with mean 1 and let \(Y_{n}=X_{1}+\cdots+X_{n}\), which is a Poisson random variable with mean \(n\). Let
\[
p(n,k)=\mathbb{P}\{Y_{n}=k\}=e^{-n}\frac{n^{k}}{k!}.
\]

\begin{enumerate}[label=(\alph*)]
    \item Use the central limit theorem to show that if \(a>0\),
    \[
    \lim_{n\to\infty}\sum_{n\leq k<n+a\sqrt{n}}p(n,k)=\int_{0}^{a}\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}\,dx.
    \]
    
    \item Show that if \(a>0\), \(n\) is a positive integer, and \(n\leq k<n+a\sqrt{n}\), then
    \[
    e^{-a^{2}}p(n,n)\leq p(n,k)\leq p(n,n).
    \]
    
    \item Use (a) and (b) to conclude that
    \[
    p(n,n)\sim\frac{1}{\sqrt{2\pi n}}.
    \]
    Stirling's formula follows immediately.
\end{enumerate}



\end{document}