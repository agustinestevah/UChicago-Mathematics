\documentclass[10pt, oneside]{article} 
\usepackage{amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry, esint, float}


\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}  

\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbZ}{\mathbb{Z}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}
\newcommand{\scA}{\mathscr{A}}
\newcommand{\curl}{\text{curl}}

\theoremstyle{definition}
\newtheorem{exmp}{Example}[section]
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}
\input{paolo-pset.tex}



\title{UChicago Complex Analysis Notes: 27000}
\author{Notes by Agust√≠n Esteva, Lectures by Robert Fefferman, Book by Stein and Shakarchi}
\date{Academic Year 2024-2025}

\begin{document}

\maketitle
\tableofcontents

\vspace{.25in}


\newpage
\section{Lectures}

\subsection{Tuesday, Mar 25: $\bbC$ as a field}
Define the Complex numbers:
\[\bbC := \{(x,y) \; | \; x,y \in \bbR\} = \bbR^2\] as a field: 
\[+: \bbC \to \bbC; \quad (a,b) + (c,d) = (a + c, b + d)\]
\[\times: \bbC \to \bbC; \quad (a,b)\times (c,d) = (ac - bd, ad + bc)\] such that for any $z = (a,b) \in \bbC,$ then 
\[z = a + ib,\] where, 
\[a = (a,0) = \Re{z}, \qquad i = (0,1), \qquad b = (0,b) = \Im{z}\]

\begin{rem}
    Why is $\bbC$ not an ordered field? Suppose it is, then there exists some $\mathcal{P}\subseteq \bbC$ of positive elements that is closed under addition and multiplication and that satisfies the trichotomy such that for any $z\in \cal P$, exactly one of the following holds: $z = 0, z\in \mathcal{P}, -z\in \cal P.$ 
    \begin{lem}
        If $z \neq 0,$ then $z^2 \in \cal P.$
    \end{lem}
    \begin{proof}
        If $z\in \cal P,$ then since $\cal P$ is closed under multiplication, $z \times z \in \cal P.$
        If $z\notin \cal P,$ then $-z \in \cal P,$ and thus $(-z)(-z) \in \cal P.$ But then $-z = (-1)(z),$ and so 
        \[(-z)(-z)= (-1)(-1)(z \times z) = z^2 \in \cal P.\]
    \end{proof}
    Consider that since $1$ is a square, then $1 \in \cal P.$ Moreover, since $-1$ is a square (in $\bbC!$), then $-1 \in \cal P.$  
\end{rem}

\begin{defn}
    Let $z\in \bbC$ such that $z = a + ib.$ We say that $\overline{z}$ is the \textbf{complex conjugate} of $z$ if 
    \[ z = a - ib.\]
\end{defn}
That is, we reflect $z$ over the real axis by flipping the sign of the imaginary line. 
\begin{rem}
    \[z \cdot \overline{z} = (a + ib)(a-ib) = (a^2 + b^2, 0) = a^2 + b^2 = |z^2|,\] by the norm defined below in (1). Suppose that $z\neq 0,$ then 
    \[z \cdot \frac{\overline{z}}{|z|} = \frac{|z|^2}{|z|^2} = 1.\] We have found the inverse of any nonzero $z\in \bbC.$ 
\end{rem}
\begin{rem}
It is easy to show the following:
    \[\overline{zw} = \overline{z} \cdot \overline{w}, \qquad  \overline{z + w} = \overline{z} + \overline{w}, \qquad |zw|^2 = |z|^2|w|^2.\]
\end{rem}

\begin{prop}
    $\bbC$ is Banach under the norm, 
    \begin{align}
    \|z\| = \|(a,b)\| = \sqrt{a^2 +b^2}    
    \end{align}
    
\end{prop}
\begin{proof}
    We will first show that the norm satisfies the triangle inequality. It suffices to show that 
    \[|z + w| \leq|z| + |w|,\] and thus we will show that 
    \[|z + w|^2 \leq (|z| + |w|)^2.\] We have by the above remarks that 
    \[|z + w|^2 = (z + w)\overline{(z + w)} = (z + w)(\overline{z} + \overline{w}) = (z\overline{z} + \overline{z}w + \overline{w}z+ w \overline{w}) = (|z|^2 + |w|^2 + z\overline{w} + \overline{z \overline{w}}) = |z|^2 + |w|^2 + 2\Re{z\overline{w}}.\] Thus, we want to show that $\Re{z\overline{w}} \leq |z||w|,$ which comes from the fact that 
    \[\Re{z\overline{w}} \leq |z||\overline{w}| = |z||w|.\]
\end{proof}

\newpage
\subsection{Thursday, Mar 27: The Topology of $\bbC$}
\begin{thm}
    $\bbC$ is complete.
\end{thm}
This theorem is in the sense of Cauchy convergence, since the least upper bound property is meaningless in a non-ordered field, such as $\bbC.$

\begin{rem}
    We denote that disk of radius $r$ around $z_0$ as 
    \[D(z_0, r) = \{z \in \bbC \; | \;|z - z_0| < r\}\]
\end{rem}

\begin{defn}
    We say that $O \subset \bbC$ is \textbf{open} if and only if for all $z_0 \in O,$ there exists some $\epsilon>0$ such that $D(z_0, r) \subset O.$
\end{defn}
It is easy to show that disks are open with the triangle inequality.

\begin{defn}
    Let $O$ be open. We say that $O$ is \textbf{connected} if, whenever $O = O_1 \cup O_2,$ where $O_1, O_2$ are open, disjoint, then at least one of the $O_1,$ $O_2$ are empty. 
\end{defn}


\begin{rem}
    How do we make the real valued $f(x) = x$ continuously differentiable on $[0,1]?$ The endpoints present a problem! We say that $f$ is differentiable at $0$ or at $1$ if the one sided limit exists and agrees with the derivative near the endpoint.
\end{rem}

\begin{defn}
    Let $O$ be an open set. A \textbf{path} is a function $\gamma: [a,b] \to O$ such that $\gamma$ is piecewise continuously differentiable. That is, there exists some finite partition $a = t_0 < t_1 < \dots < t_n = b$ such that $\gamma$ is continuously differentiable on each closed interval $(t_{k-1}, t_k)$ and 
    \[\lim_{t \to t_{k-1}^+} \gamma'(t) = \gamma_+'(t_{k-1}) = \lim_{h\to 0^+} \frac{\gamma(t_{k-1} +h) - \gamma(t_{k-1})}{h}\] and similarly for $t_k.$
\end{defn}

\begin{thm}
    If $O$ is pathwise connected, then it is connected.
\end{thm}
\begin{proof}
    Suppose $O$ is disconnected, then $O = O_1 \sqcup O_2$ and take $[a,b] = \gamma^{-1}(O_1) \sqcup \gamma^{-1}(O_2)$ as a disconnection of the interval, a contradiction!
\end{proof}

\begin{defn}
    Let $O$ be open. We say that a \textbf{polygonal path} inside  of $O$ is a path made up of only horizontal and vertical lines. 
\end{defn}

\begin{thm}
    Suppose $O$ is connected, then $O$ is polygonally connected. 
\end{thm}
\begin{proof}
    Let $z_0 \in O.$ We will show that 
    \[A = \{z \;  | \; \exists \text{ polygonal path between $z_0$ and $z$} \}\] is the same as $O.$ We will first show that $O$ is open. Let $z\in A,$ since $O$ is open, there exists some $r>0$ such that $D(z, r) \subseteq O.$ We will show that for any $z' \in D(z,r),$ $z' \in A.$ It suffices to show that disks are polygonally connected. 

    Since disks are convex, there exists a straight line connecting $z, z'.$ We claim that the imaginary component of this line is in the disk, which is because of the Pythagorean identity (or because $\Im{r} \leq |r|.$) By convexity, the straight line (i.e, the real component) between the imaginary line and $z'$ is in the disk. Thus, we can polygonally connect $z$ and $z'.$

    Thus, $A$ is open. Let $B$ be the set of points in $O$ that cannot be polygonally connected. Evidently, $A \cap B = \emptyset.$ By dichotomy, $A \cup B = O.$ Evidently, $z_0 \in A.$ Clearly, $B$ is open, and so $B$ must be empty and $A = O.$
\end{proof}

\begin{exmp}
Let $t\in [0,1].$ \begin{enumerate}
    \item The straight path from $z_2$ to $z_1$:
    \[\gamma(t) = tz_1 + (1-t)z_2\]
    \item The straight path from $z_1$ to $z_2$ is 
    \[\gamma(t) = (1-t)z_1 + tz_2\]
    \item The circle centered at $z_0$ of radius $r$ counterclockwise. 
    \[\gamma(\theta) = z_0 + r\cos\theta  + ir\sin\theta = z_0 + e^{ir\theta}, \qquad \theta \in [0, 2\pi)\]
\end{enumerate}
\end{exmp}

\begin{defn}
    Suppose $O \subseteq \bbC$ be open, and let $f: O \to \bbC.$ We say that $f$ is \textbf{continuous} at $z_0 \in O$ if 
    \[\lim_{z \to z_0}f(z) = f(z_0), \quad z \in O.\] We say that $f$ is differentiable at $z_0 \in O$ if 
    \[\lim_{h\to 0}\frac{f(z_0 + h) - f(z_0)}{h} = f'(z_0), \quad h \in \bbC\]
\end{defn}
Continuity in $\bbC$ is identical to continuity in $\bbR^2,$ since they are identical as metric spaces. But dividing in $\bbR^2$ makes no sense, so the differentiability is completely different!
\begin{exmp}
    \begin{enumerate}
        \item Suppose $f(z) = z^2,$ then 
        \[\frac{(z + h)^2 - z^2}{h} = 2z + h \to 2z = f'(z)\]
        \item Suppose $f(z) = \overline{z}.$ Then at the origin, 
        \[\lim_{h\to 0}\frac{\overline{(0 + h)} - \overline{0}}{h}= \lim_{h\to 0}\frac{\overline{h}}{h},\] but the looking at a purely real component, the limit approached $1.$ Looking at a purely imaginary components, the limit approaches $-1.$ Oops!
    \end{enumerate}
\end{exmp}

\newpage
\subsection{Tuesday, Apr 1: The Complex Integral}
Suppose $f: [a,b] \to \bbC.$ Then, if the limit exists,
\[f'(t) = \lim_{h\to 0}\frac{f(t+  h) - f(t)}{h}.\] All the normal quotient, product, and chain rules apply.

\begin{defn}
    We define the \textbf{integral} of $f: [a,b] \to \bbC,$ where $f(t) = u(t) + iv(t),$ then 
    \[\int_a^b f(t)dt = \int_a^b u(t)dt + i \int_a^b v(t)dt\]
\end{defn}

\begin{prop}
    (Linearity) Suppose $f, g: [a,b] \to \bbC,$ then 
    \[\int_a^b f + g = \int_a^b f + \int_a^b g\]
    (Scalar Linearity) Suppose $c \in \bbC,$ then 
    \[\int_a^b c f = c\int_a^b f\]
    (Triangle Inequality) Suppose $f: [a,b] \to \bbC,$ where $f$ is continuous. Then 
    \[\left| \int_a^b f\right|\leq \int_a^b |f|\]
\end{prop}
\begin{proof}
    (Linearity) We have that 
    \begin{align*}
        \int_a^b f + g &= \int_a^b \left[(u_f + u_g) + i(v_f + v_g)\right]\\
        &=\int_a^b( u_f + u_g) + i\int_a^b(v_f + v_g)\\ 
        &= (\int_a^b u_f + i \int_a^b v_f) + (\int_a^b u_g + i \int_a^b v_g)\\
        &= \int_a^b f + \int_a^b g
    \end{align*}
    (Scalar Linearity) Suppose $c\in \bbR,$ then
    \begin{align*}
        \int_a^b cf = \int_a^b c u + i\int_a^b c v = c(\int_a^b f)
    \end{align*}
    For $i \in \bbC,$ we have that 
    \begin{align*}
        \int_a^b if &= \int_a^b iu - v\\
        &= \int_a^b-(v - iu)\\
        &= -\int_a^b v - iu\\
        &= i\left(\int_a^b u + i \int_a^b v\right)\\
        &= i \int_a^b f
    \end{align*}
    Let $z = \alpha + i \beta \in \bbC.$ Then 
    \[\int_a^b z f = \int_a^b \left[\alpha f + i\beta f\right] = \int_a^b \alpha f  + \int_a^b i\beta f = \alpha \int_a^b f + i\beta \int_a^b f = z \int_a^b f\]

    (Triangle inequality). Given any $z\in \bbC,$ there exists some $\alpha \in \bbC$ with $|\alpha| = 1$ such that $\alpha z = |z|.$ To see this for $z\neq 0,$ note that $\alpha = \frac{|z|}{z}.$ Thus, there exists some $\alpha \in \bbC$ with $|\alpha| = 1$ such that
    \begin{align*}
        \left|\int_a^b f\right| &= \alpha \int_a^b f = \int_a^b \alpha f\\
        &= \int_a^b \alpha u + i \int_a^b \alpha v= \int_a^b \alpha u\\
        &= \int_a^b au + i\int_a^b bu= \int_a^b \Re{\alpha f}\\
        &\leq \int_a^b |\Re{\alpha f}|
        \leq \int_a^b |\alpha f| = \int_a^b |f|
    \end{align*}
\end{proof}

\begin{thm}
Suppose $f: [a,b] \to \bbC$ and $f'$ is continuous on $[a,b].$ Then 
\[\int_a^b f' = f(b) - f(a)\]
\end{thm}

\begin{remk}
    Let $f:O \to \bbC$ be continuous, where $O \subset \bbC$ is open. Suppose $\gamma: [a,b] \to O$ is a path in $O.$ Partition $\gamma$ into $\{z_k\}$ such that $z_k = \gamma(t_k).$ Then we estimate the integral along the curve by 
    \[\lim_{\max |z_k - z_{k-1}|}\sum_{k=1}^n f(z_k)[z_k - z_{k-1}] = \lim_{\max|t_k - t_{k-1}|}\sum_{k=1}^n f(\gamma(t_k)) \frac{\gamma(t_k) - \gamma(t_{k-1})}{t_k - t_{k-1}}(t_k - t_{k-1}) = \int_a^b f(\gamma(t))\gamma'(t)dt\]
\end{remk}
\begin{defn}
    Define the quantities as in the above remark, then the \textbf{line integral} of $f$ over $\gamma$ is 
    \[\int_\gamma f(z)dz = \int_a^b  f(\gamma(t))\gamma'(t)dt\]
\end{defn}

\begin{prop}
    (Linearity) \[\int_\gamma f + g = \int_\gamma f + \int_\gamma g\]
    (Estimation) 
    \[\int_\gamma f(z)dz \leq \max_{t\in [a,b]}|f(\gamma(t))|\text{ length}(\gamma)\] where 
    \[\text{length}(\gamma) = \lim_{\max |t_k - t_{k-1}|}\sum_{k=1}^n \left|\gamma(t_k) - \gamma(t_{k-1})\right| = \int_a^b |\gamma'(t)|dt\]
\end{prop}
\begin{proof}
    (Estimation)
    \[\left|\int_\gamma f(z)dz\right| = \left|\int_a^bf(\gamma (t))\gamma'(t) dt\right| \leq \int_a^b |f(\gamma(t))\gamma'(t)| dt \leq \max_{t \in [a,b]}|f(\gamma(t))|\int_a^b |\gamma'(t)|dt = \max_{t\in [a,b]}|f(\gamma(t))|\text{ length}(\gamma)\]
\end{proof}

\begin{exmp}
    \begin{enumerate}
        \item \[\gamma(t) = (1-t)z_1 + t z_2, \qquad t\in [0,1]\] is the straight line from $z_1$ to $z_2.$ Then intuitively:
        \[\text{length}(\gamma)= |z_2 - z_1|\] By definition:
        \[\text{length}(\gamma) = \int_0^1 |\gamma'(t)|dt = \int_0^1 |z_2 - z_1|dt = |z_2 - z_1|\]
        \item 
        \[\gamma(\theta) = z_0 + r[\cos(\theta) + i\sin(\theta)], \qquad \theta \in [0, 2\pi]\] is the circle of radius $r$ centered at $z_0$ with counterclockwise orientation. 
        \[\text{length}(\gamma) = \int_0^{2\pi} \gamma' = r\int_0^{2\pi} |\sin(\theta) + i\cos(\theta)| = 2\pi |r|\]
    \end{enumerate}
\end{exmp}

\newpage
\subsection*{Thursday, Apr 3: Properties of the Integral}

\begin{thm}
Suppose $(f_n)$ are continuous functions on open $O \subseteq \bbC.$ Assume that for some path $\gamma$ in $O,$ (a path being in $O$ means that $\gamma([a,b]) \subseteq O$). Assume that $f_n(z) \to f$ uniformly on $\{\gamma(t) \mid t \in [a,b]\}.$ Then 
\[\int_\gamma f_n(z)dz  \to \int_\gamma f(z)dz\]

\end{thm}
\begin{proof}
Since $f_n \to f$ uniformly, $\sup_{z}|f_n(z) - f(z)| < \frac{\epsilon}{\text{length}(\gamma)  + 1}$ for large $n.$ 
\begin{align*}
\left|\int_\gamma f_n(z)dz - \int_\gamma f(z)\right| &= \left|\int_\gamma f_n(z) - f(z)\right|\\
&\leq \sup_{t\in [a,b]}|f_n(\gamma(t) - f(\gamma(t)))|\text{length}(\gamma)\\
&< \epsilon
\end{align*}

\end{proof}

\begin{thm}
Suppose $f$ is continuous on open $O\subseteq \bbC$ and $f: O \to \bbC.$ Let $\gamma$ be a path in $O.$ If $f$ has a primitive on $O$ (i.e. there is some $F(t)$ in $O$ such that $F'(z) = f(z)$ for all $z\in O$), then \[\int_\gamma f(z)dz= F(\gamma(b)) - F(\gamma(a))\]
\end{thm}

With these conditions, these immediately implies path independence, as long as the paths start and end at the same time, and that this also implies that a line integral yields $0$ along a closed loop.
\begin{proof}
    Suppose $\gamma'$ is continuous. Then 
    \[\int_\gamma f(z)dz = \int_a^b f(\gamma(t))\gamma'(t)dt = \int_a^b F'(\gamma(t))\gamma'(t)dt = \int_a^b (F\circ \gamma)'(t)dt = F(\gamma(b)) - F(\gamma(a))\]

    For the general case, we only know that $\gamma'$ is piecewise continuous. Partition $[a,b]$ into $a = t_0 < t_1 < \dots < t_n = b$ such that $\gamma'$ is continuous on each subinterval $\{[t_{i-1},t_i ]\}_{i \in [n]}.$ Then we use the degenerate case above for each subinterval
    \[\int_\gamma f(z)dz = \int_a^b F'(\gamma(t))\gamma'(t)dt = \sum_{i = 1}^n \int_{t_{i-1}}^{t_i}F'(\gamma(t))\gamma'(t) = \sum_{i=1}^n \left[F(\gamma(t_i)) - F(\gamma(t_{i-1}))\right] = F(\gamma(b)) -F(\gamma(a))\]
\end{proof}

What happens when we have the same path, $\gamma,$ but the parametrization of $\gamma$ changes? That is, what if there is another parameterization of the same path? 

\begin{thm}
    Suppose $\gamma: [a,b] \to O,$ where $O\subseteq \bbC$ is open, and suppose $f: O \to \bbC$ is continuous. Suppose further that $\phi: [c,d] \to [a,b]$ such that $\tilde{\gamma}(t) = \gamma(\phi(t))$ for $t\in [c,d].$ If $\phi'$ is continuous and $\phi$ is a bijection and $\phi' >0$ ($\phi$ and $\gamma$ have the same orientation), then 
    \[\int_{\tilde{\gamma}} f(z)dz = \int_\gamma f(z)dz\]
\end{thm}

\begin{proof}
Recall the standard change of variables formula from analysis, if
\[\int_{[c,d]} f(\phi(x))|\phi'(x)|dx = \int_{\phi([c,d])}f(y)dy\]
    By definition
    \begin{align*}
        \int_{\tilde{\gamma}} f(z)dz &= \int_c^d f(\tilde{\gamma}(t))\tilde{\gamma}'(t) dt\\
        &= \int_c^d f(\gamma(\phi(t)))\tilde{\gamma}'(t)dt\\
        &= \int_c^d f(\gamma(\phi(t)))\gamma'(\phi(t))\phi'(t)dt\\
        &= \int_c^d f(\gamma(\phi(t)))\gamma'(\phi(t))|\phi'(t)|dt\\
        &= \int_a^b f(\gamma(s))\gamma'(s)ds\\
        &= \int_\gamma f(z)dz
    \end{align*}
If $\phi' < 0,$ then we must compensate where we put in $|\phi'(t)|$ by putting in a negative sign in front of the integral, and thus when the orientation of the parameterization is opposite, the integrals are opposite.
\end{proof}


\begin{rem}
    Consider the function $f: \bbR \to \bbR$ defined by 
    \[f(x) = \begin{cases}
        e^\frac{-1}{x^2}, \qquad x >0\\
        0, \qquad \quad x\leq 0
    \end{cases}.\] It is not hard to show that, although $f(x)$ is smooth (infinitely differentiable), it is not analytical! That is, there does not exist a converging power series at every $x\in \bbR$ that equals $f(x).$ The converse clearly holds for $\bbR.$

    We will show that if $O \subset \bbC$ is open, and there is a holomorphic function on $O,$ then if there is a disk around any point $z_0 \in O,$ then the function is analytical!
\end{rem}

\begin{prop}
    Let $f(z) = \sum_{n=1}^\infty a_n z^n.$ Then there exists some $\rho \in [0, \infty]$ called the \textbf{radius of convergence},  such that if $|z| < \rho,$ then the series absolutely converges. If $|z| > \rho,$ then $\{a_nz^n\}$ is unbounded.
\end{prop}
\begin{exmp}
    \begin{itemize}
        \item Consider 
        \[f(z) = \sum_{n=1  }^\infty z^n,\] then $\rho = 1$ since it is a geometric series if $z < 1$ and obviously diverges if $|z|\geq 1.$ When $|z| = 1,$ try to see for yourself why $z = i$ diverges. 
        \item The classic 
        \[f(z) = \sum_{n=1}^\infty \frac{z^n}{n!},\] which converges everywhere! That is. $\rho = \infty.$
    \end{itemize}
\end{exmp}

\newpage
\subsection{Tuesday, Apr 8: Power Series}
We recalled Theorem 6 and 7 from the previous class.

\begin{rem}
    Consider the following change of variable: 
    \[\varphi: [a,b]\to [a,b], \quad \varphi(t) = a + b - t,\] then note that $\varphi$ makes $\gamma$ run in reverse
\end{rem}

\begin{rem}
    A general power series, centered at some $z_0 \in O \subset \bbC,$ is defined to be the formal sum
    \[\sum_{n=1}^\infty a_n(z - z_0)^n.\] We will usually just take $z_0 = 0.$ 
\end{rem}

\begin{prop}
    For any power series $ \sum_{n=1}^\infty a_n z^n,$ the radius of convergence is 
    \[\rho = \sup\{|z| \mid (a_nz^n) \text{ is bounded}\}\]
\end{prop}
\begin{proof}
    If $|z_0| > \rho,$ then $(a_n z_0^n)$ is unbounded, and thus the series cannot converge, since the terms do not go to zero.

    If $|z_0| < \rho,$ then let $\epsilon >0$ such that $|z_0| = \rho - \epsilon.$ Consider that since $|a_n|(\rho - \frac{\epsilon}{2})^n$ is bounded by some $M$ since it is less than $\rho.$
    \begin{align*}
        \sum_{n=1}^\infty |a_n||z_0|^n &= \sum_{n=1}^\infty(|a_n|( \rho - \frac{\epsilon}{2}))^n \frac{|z_0|^n}{(\rho - \frac{\epsilon}{2})^n}\\
        &\leq M\sum_{n=1}^\infty \left(\frac{|z_0|}{(\rho - \frac{\epsilon}{2})}\right)^n\\
        &< \infty,
    \end{align*}
    The series converges geometrically since $\frac{|z_0|}{(\rho - \frac{\epsilon}{2})} < 1.$
\end{proof}

\begin{lemma}
    We claim that 
    \[\frac{w^n - w^n}{z - w} = z^{n-1} + z^{n-2}w + \dots w^{n-1}\]
\end{lemma}
\begin{proof}
   Note that 
    \[(z-w)\left(z^{n-1} + z^{n-2}w + \dots w^{n-1}\right) = z^n - w^n\]
\end{proof}

\begin{thm}
    If $|z| < \rho,$ and 
    \[f(z) = \sum_{n=0}^\infty a_n z^n,\] then $f$ is differentiable at $z$ and 
    \[f'(z) = \sum_{n=0}^\infty n a_n z^{n-1}\]
\end{thm}
\begin{proof}
Let $|z_0| = \rho - \epsilon$
    The difference quotient is given by 
    \begin{align*}
        \frac{f(z_0 + h) - f(z_0)}{h} &= \frac{\sum_{n=1}^\infty a_n (z_0 + h)^n - \sum_{n=1}^\infty a_nz_0^n}{h}
    \end{align*}
Note since the terms $a_n z_0^{n-1}$ are geometric, then the series 
\[\sum_{n=1}^{\infty} n a_n z_0^{n-1}\] converges (one can check this with the ratio test).
    Thus, consider that 
\begin{align*}
    &\left|\frac{\sum_{n=0}^\infty a_n (z_0 + h)^n - \sum_{n=1}^\infty a_nz_0^n}{h} - \sum_{n=0}^\infty na_n z_0^{n-1}\right| =\\ &= \left|\sum_{n=0}^N a_n\frac{ (z_0 + h)^n - z_0^n}{h} + \sum_{N + 1}^\infty \frac{ (z_0 + h)^n - z_0^n}{h} - \sum_{n=0}^\infty na_n z_0^{n-1} - \sum_{N+1}^\infty  na_n z_0^{n-1}\right|\\
    &\leq \left|\sum_{n=0}^N a_n\frac{ (z_0 + h)^n - z_0^n}{h} - na_nz_0^{n-1}\right| + \left|\sum_{N+1}^\infty a_n\frac{ (z_0 + h)^n - z_0^n}{h}\right| + \left|na_nz_0^{n-1} \right| \\
    &\xrightarrow{h\to 0} \left|\sum_{n=0}^N na_nz_0^{n-1} - na_nz_0^{n-1}\right| + \left|\sum_{N+1}^\infty a_n\frac{ (z_0 + h)^n - z_0^n}{h}\right| + \left|na_nz_0^{n-1} \right|\\
    &= \left|\sum_{N+1}^\infty a_n\frac{ (z_0 + h)^n - z_0^n}{h}\right| + \left|\sum_{N+1}^\infty na_nz_0^{n-1} \right|
\end{align*}
Since $\sum_{N+1}^\infty na_nz_0^{n-1} $ converges geometrically, then the sum goes to zero as $N \to \infty.$ Using Lemma 1, we note that if $h < \frac{\epsilon}{2}$ and $|z_0| = \rho - \epsilon,$ then 
\[|z_0  + h| \leq |z_0| + |h| < \rho - \frac{\epsilon}{2}\]
\[\left|\sum_{N+1}^\infty a_n\frac{ (z_0 + h)^n - z_0^n}{h}\right| = \sum_{N+1}^\infty |a_n|\left|\frac{ (z_0 + h)^n - z_0^n}{(z_0 + h) - z_0}\right| \leq \sum_{N+1}^\infty |a_n|\sum_{k=0}^{n-1} |(z_0 + h)|^k |z_0|^{n-1-k}  < \sum_{N+1}^\infty n|a_n|  (\rho - \frac{\epsilon}{2})^{n-1} \xrightarrow[N\to \infty]{} 0\] since it converges geometrically again
\end{proof}

\begin{cor}
    $f(z) = \sum_{n=0}^\infty a_n z^n$ is infinitely differentiable for all $z$ such that $|z| < \rho.$ Moreover, 
    \[a_n = \frac{1}{n!}f^{(n)}(0)\]
\end{cor}
\begin{proof}
    By Theorem 8, we have that for all $|z| < \rho$
    \[f'(z) = \sum_{n=0}^\infty n a_n z^{n-1}.\] Note that $f'(z)$ has a bigger radius of convergence than $f(z)$ since $na_n z^{n-1}$ is still bounded and is still geometrically 'small.' Thus, we apply Theorem 8 again to $f'(z),$ then 
    \[f''(z) = \sum_{n=0}^\infty n(n-1)a_n z^{n-2}.\] For the second claim, 
    \[f(z) = a_0 + a_1z + \dots +  a_nz^n + \cdots\] Then $f(0) = a_0.$ Also, $f'(z) = a_1 
 + \dots na_n z^{n-1}$ and so $f'(0) = a_1.$ Also, 
 \[f''(z) = 2a_2z + \dots  + n(n-1)z^{n-2} + \cdots,\] and so $f''(0) = 2a_2.$ Inducting yields the result.
\end{proof}

\end{document}